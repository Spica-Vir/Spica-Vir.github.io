[ { "title": "Cygwin as an Alternative Linux Environment on Windows", "url": "/posts/Cygwin-as-an-Alternative-Linux-Environment-on-Windows/", "categories": "Technique, OS, Research, DFT", "tags": "linux, windows", "date": "2023-11-05 23:32:03 +0000", "snippet": "Stories about Windows+LinuxIt was late 2019 and early 2020 when I was firstly exposed to Linux system and began to learn how an OS works. I am not saying that I ‘learned’ it since it is a lifelong learning process. VMware Player was the first virtual machine platform that I learned to use, thanks to the molecular dynamics lecture delivered by Prof. W. Qi (齐卫宏 教授) at NWPU - by the way he gave away textbooks by him for free, which I keep till today as an interesting souvenir and reference. It (the software!) was not good for many reasons, frankly speaking. It was slow and unstable due to not running on the actual hardware, and to transfer files a plugin was needed to load the disk in ‘real’ OS as a virtual optical drive. The good thing was that virtual OS was not limited by the actual hardware used, so Android, iOS etc. developers can test codes on a x86 device, but that hardly mattered to me. The popular practice among Computation Department students was enabling the dual OS (Linux + Windows) option. That completely isolates 2 OSs and only the hardware is shared, bringing troubles of file transfer.Meanwhile, or even earlier, the first generation of Windows Subsystem for Linux (WSL) was released. It was a real game changer, as it was smoothly integrated into the file system and did not even rely on a virtual machine platform. I am not pretending to be a computer scientist, but WSL1 seems to run Linux executable just as smoothly as Windows executable. I compiled and ran VASP on my laptop for several weeks in early 2020’s lockdown. That strategy brought many troubles for future developing and unfortunately Microsoft is always the opposite of open-source. WSL1 was quickly replaced by WSL2, which is a light-weighted virtual machine sharing the file system with Windows. The performance was reduced as the compromise for a fully functioning Linux environment with graphic user interface (GUI). I am generally happy with that since indeed there are some complex and even ridiculous issues with WSL1 and the performance, in terms of CPU and disk, is not that badly deteriorated. The noticeable trouble is GUI, and here is the dilemma: WSL1 - better performance but no GUI; WSL2 - reduced performance but at least has GUI. This becomes particularly annoying when there is a proper graphic card on the laptop but for sure it is just idling around while CPU is groaning.Windows seems to be extremely unpopular for atomic modelling, except for the really brilliant VESTA and others, the option seem to be Materials Studio, a good example of how science is capitalized and monopolized. Making GNU and FOSS visualization tools available to Windows is therefore important. Cygwin is a less well-known option compared to those mentioned above but it solves my GPU troubles recently.CygwinCygwin vs WSLThe fundamental difference between Cygwin and WSL is that Cygwin provides libraries during compilation in such a way that Linux codes are ‘wrapped’ and the compiled executable is a windows executable dynamically linked to Cygwin libs, while WSL is a Linux virtual machine that generates Linux executable. Because of this, Cygwin executable has limited portability and availability (not all Linux executable support Cygwin), which typically runs only in Cygwin environment (not even Windows) unless dependencies are correctly sorted out in Windows environment. But as it is, in principle, a windows exe file, so it runs in the same way as other installed software. WSL compiles executable for all Linux machines as long as the dependency, OS distribution, hardware etc. are consistent. It also has no extra requirement on software, which means if a code runs on a similar Linux machine, it also runs on WSL. Its drawbacks, as discussed in the previous section, is failing to utilize hardware.In terms of file management, the root directories of both can be visited via file manager. WSL can visit windows disk in /mnt, but Cygwin cannot visit files in the main OS, so files have tobe copied into Cygwin installation directory for its terminal to visit.Package managementThe installation tool is also the package management tool for Cygwin, i.e., apt or yum for other Linux distributions. The root directory is Cygwin installation directory. Here is a screenshot of Cygwin package manager user interface. ‘Skip’ means not-yet-installed packages.XMing and GraphicsThe graphic user interface (GUI) can be enabled following Microsoft’s Tutorial, though my personal attempts in installing a GUI desktop always ended up in failure. As far as I am aware of, Cygwin requires X Window System (My supervisor called it an old school way but I don’t agree with him) to run GUI apps. Xming is a free, open source package for Windows. For Cygwin, X11 components are needed. In package manager, search for ‘xclock’ to add a very basic X11 application and all dependencies to Cygwin environment.After finishing installations, to run GUI apps, Xming should be launched as an idling server. The screenshot below shows the default option. GUI apps in Cygwin are launched in separate windows. Other options are for X Windows based desktop applications which displays the Linux environment as a proper graphic OS.Then use the default settings. Since the display number is ‘0’ for Xming server, in Cygwin, use export DISPLAY=:0 to set the display port for client.Run xclock.Programs on CygwinXCrySDenI really lik XCrySDen as a free visualization tool for atomic structures and electron properties. The compiled distribution and instructions are available online.GDISGDIS is a free, open source visualization tool developed in Curtin, West Australia, which does a neat symmetry analysis job especially for complex molecular crystals, as it was initially developed for classical force field people. As a DFT guy, I am beaten hard by them every fortnight. It requires libgtk-2.0 and libgtkglext and their ‘-devel’ distributions as compiling GDIS requires pkg-config." }, { "title": "Revisiting SSH - Key Pair and Configuration file", "url": "/posts/SSH-revisit/", "categories": "Technique, SSH", "tags": "linux", "date": "2023-09-14 19:33:49 +0100", "snippet": "Recently I reset my WSL virtual machine, which forces me to regenerate ssh key pair for ARCHER2. Some useful commands and configurations are documented here for reference. Tested on 12th September, 2023.Generate and copy SSH keySSH key is a requirement for ARCHER2, but not for other clusters. It is not until recently that I found that can save a lot of time. To generate a hashed ssh public/private key pair, use:~$ ssh-keygenBy default the public part is saved in ~/.ssh/id_rsa.pub and the private part is in ~/.ssh/id_rsa. When connecting server via SSH, the private key stored locally will be compared with the public part stored on the host. If that is a match, the connection is automatically set up. Therefore, the public key should be copied to the server:~$ ssh-copy-id user@serverThe public key is saved in ~/.ssh/authorized_keys by default. Alternatively, if the command ssh-copy-id is not available, use the following line to send a command to server:~$ ssh user@server &#39;mkdir -p ~/.ssh &amp;amp;&amp;amp; cat &amp;gt;&amp;gt; ~/.ssh/authorized_keys&#39; &amp;lt; ~/.ssh/id_rsa.pubWith public key the user can access server without password, as long as the corresponding private key is stored in ~/.ssh. However, according to my tests, password is still required when accessing clusters including Imperial CX1 and ARCHER2. Clusters might have a separate host to deal with logins, which improves security. But the server in the lab can be accessed with public key only.Configuration fileImportant logging in information can be saved in the ~/.ssh/config file, so the user does not need to type the lengthy ssh commands every time. Definitions of all the keywords can be referred to by the man ssh_config command. Keywords that I typically use are listed below.Host alias1 HostName address or ip User login account LocalForward [bind_address]:port1 host:port2 ForwardX11 yesHost alias2 HostName address or ip User login accountLocalForward specifies a local port and a remote port on the host through which commands, data etc. are transferred via a secured channel, so by calling ‘port1’ locally the ‘port2’ on the server is called. That is equivalent to ssh -L command. ForwardX11 is equivalent to ssh -X, which establishes X11 forwarding. Graphical software on the host can access the local X11 services and be displayed on the local monitor.After setting the config file, use the following commands for connection and file transfer:~$ ssh alias1~$ scp local/file alias1:host/destination" }, { "title": "Optimized compilation of FFTW3", "url": "/posts/Optimized-Compilation-of-FFTW3/", "categories": "Technique, Parallel Computing", "tags": "linux, FFTW", "date": "2022-12-30 16:26:05 +0000", "snippet": "The optimized compilation of FFTW3 (version 3.3.10) is explored in this post. Even though some questions remains to be answered, it currently seems to be the optimal procedure. Tested on NHPC101 (OpenSUSE Leap 15.3), Dec. 29, 2022.FFTW is a portable package for fast Fourier transformation (FFT), which is useful in multiple applications. One of its important applications in DFT is that it transforms and diagonalizes matrices such as Fock &amp;amp; overlap matrices between reciprocal and real space (I am not very clear about the details at the current stage), so it is a common prerequisite of DFT codes. It also helps solving the long-range Coulomb interactions in molecular dynamics, for example, the KSPACE package of LAMMPS requires FFT as well.Environment Compiler: GCC 11.3.0 MPI: MPICH 4.0.2Paths to binary executable, header files and static libs of GCC and MPICH are add to the environmental variable ${PATH}, ${INCLUDE} and ${LD_LIBRARY_PATH}respectively. To use GCC compiler, set CC=gcc, CXX=g++ and FC=gfortran (the later two are probably not needed since FFTW3 is written in C). Using environment modulues is recommended.CompilationMinimal proceduresDownload the source code from its website. The compilation of FFTW3 follows the traditional make procedures, so the minimal installation steps are:~$ tar -zxvf fftw-3.3.10.tar.gz~$ cd fftw-3.3.10~$ ./configure~$ make~$ make installThat gives a serial version of FFTW3. To optimize the compilation, extra compilation options are needed. The command ./configure --help gives necessary information of command-line flags.Explanation of optionsThe following example gives a compilation of executable and libs optimized for single &amp;amp; double precision float, static &amp;amp; dynamic libs, MPI, OpenMP, threading and Intel i7-7700 CPU.Firstly, build the single-precision libs:~$ ./configure --prefix=PREFIX --enable-single --enable-shared=yes --enable-static=yes --enable-mpi --enable-openmp --enable-threads --enable-sse --enable-sse2 --enable-avx --enable-avx2 --enable-fma ~$ make~$ make installThen, clean the linked files from the previous step, keep the settings and build the double-precision libs:~$ make clean~$ ./configure --prefix=PREFIX --enable-shared=yes --enable-static=yes --enable-mpi --enable-openmp --enable-threads --enable-sse2 --enable-avx --enable-avx2 --enable-fma ~$ make~$ make installBy default, make executes a global installation at ‘/usr/local/’, which requires sudo. Alternatively, the --prefix=PREFIX option builds the executable at the user-specified location.The double-precision float version is compiled without --enable-single. In some occasions, the single-precision float libs are supported in codes to trade precision for acceleration.Static libs ending with ‘.a’ are generated by default. Dynamic libs with ‘.so’ are generated with --enable-shared, which takes less space since it functions as an index. It is recommended to compile dynamic libs with dynamic FFTW3 libs and to compile static libs with the static one. It is possible to compile static libs with dynamic FFTW3 libs but another flag -fPIC should be added. Not tested.--enable-mpi, --enable-openmp and --enable-threads are valid only MPI has been loaded in the environment. To activate the later two, the MPI should also support OpenMP and multi-threading, which is widely supported in modern MPI implementations.Different CPU architectures support different sets of instructions. FFTW3 can optimize its performance according to specific CPU architectures during compilation. To get the supported sets of instructions of the current server, use the following command:~$ cat /proc/cpuinfo | grep flags | uniqflags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb invpcid_single pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt intel_pt xsaveopt xsavec xgetbv1 xsaves dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp md_clear flush_l1d arch_capabilitiesNote: --enable-sse requires a single-precision compilation.Available libsIn ‘PREFIX/lib64’, or ‘PREFIX/lib’, 4 versions ending with nothing, ‘_mpi’, ‘_omp’, ‘_thread’ are generated, of which the names are self-explanatory. Libs begin with ‘libfftw3’ stands for double-precision libs and ‘libfftw3f’ for single-precision ones. They can be installed under the same directory but need 2 makes as instructed above.Problems with Intel compilersCompilation with Intel OneAPI compilers (version 2022.1.2.146 and 2023.0.0) always fail with the error message of unknown flag -ansi-alias. This flag seems to be a universal one but the error only occurs when compiling the mpi version, so Intel compilers should be ok if the serial version is needed, i.e., --enable-mpi, --enable-openmp and --enable-threads commands should be avoided (it is not clear whether the later 2 work without the first flag). Using either the classic C/C++ compiler, CC=icc, or the modern DPC++/C++ one, CC=icx cannot address this problem. Compilation with a more recent MPICH 4.0.2 + Intel DFC++/C++, rather than the built-in Intel MPI did not solve this problem as well. This section might be updated if more hints are available." }, { "title": "LAMMPS compilation and integration with Python", "url": "/posts/LAMMPS-compilation-and-integration-with-Python/", "categories": "Technique, Parallel Computing", "tags": "linux, LAMMPS", "date": "2022-12-30 15:32:20 +0000", "snippet": "Procedures to Compile LAMMPS as both static and dynamic libs are summarized in this post. When compiled as the dynamic lib, the integration of LAMMPS and python environment is briefly explored. The compiled version of LAMMPS is 23Jun2022, with OpenMP threading, GPU acceleration and FFT by FFTW3. Tested on NHPC101 (OpenSUSE Leap 15.3), from Dec. 28 to Dec. 30 2022.PrerequisitesEnvironment establishment: cmake 3.23.1 fftw 3.3.10 Intel OneAPI 2022.1.2.146 NvidiaHPC-SDK 22.3 (CUDA 11.6)Basic information about NHPC101: CPU: Intel core i7-7700 GPU: Nvidia Quadro P400cmakeThe compilation of cmake is rather clear, which is also given in LAMMPS manual. All the compilations are based on cmake.FFTW3Trivial molecular dynamics calculations by LAMMPS does not require FFT. The KSPACE package, and probably other packages involving reciprocal space, requires FFT to solve long-range interactions. It is also pointed out in the document that, without FFTW3, LAMMPS can also build FFT libs by the built-in KISS package. FFTW3 can probably improve the performance but for sure brings more troubles in compilation. See this page.The compilation procedures of FFTW3 libs are given in Optimized Compilation of FFTW3. The built-in FFTW wrapper of Intel OneAPI is not sufficient to meet the needs. As suggested in the manual, a single-precision FFTW3 lib is used.Intel SuiteFor Intel CPUs, the Intel suite are helpful to get the optimal accelerations especially when combined with the INTEL package. This package also offers moderate acceleration when the code is compiled with other compilers. It should be noted that the current implementation of LAMMPS supports classic C/C++ compilers only, i.e., CC=icc and CXX=icpc. The DPC++/C++ compiler (icx) leads to errors.GPU accelerationNvidia compilers are not required, so the NvidiaHPC-SDK suite is not necessarily needed, but CUDA is required. The GPU package is a relatively independent one, which can be skipped without interfering the integrity of the code. To include GPU acceleration, the following paths must be added before compilation if the CUDA is not loaded individually by environment modulus, and it should be noted that NvidiaHPC-SDK suite should not be loaded as a whole since the Intel suite is needed:~$ export PATH=&quot;$PATH:/path/to/NvidiaHPC-SDK/22.3/cuda/11.6/bin&quot;~$ export LD_LIBRARY_PATH=&quot;${LD_LIBRARY_PATH}:/path/to/NvidiaHPC-SDK/22.3/cuda/11.6/lib64&quot;~$ export LD_LIBRARY_PATH=&quot;${LD_LIBRARY_PATH}:/path/to/NvidiaHPC-SDK/22.3/cuda/11.6/extras/CUPTI/lib64&quot;CompilationLAMMPS can be compiled either statically or dynamically. Both can produce executable. The previous option is similar to the traditional computational codes, which executes jobs and give results as a blackbox and can be called by an external application. The latter one can be loaded as a dynamic lib (which is much easier than being loaded as a static lib) and enables interactive developing, such as being integrated with atomic simulation environment (ASE). But dynamic linking requires more settings as the compilation does not really link the required libs but records their paths only.Static buildThe following options enable a static linking:~$ cmake ../cmake --install-prefix /path/to/lammps/23Jun2022/ -D LAMMPS_MACHINE=stc -D CMAKE_CXX_COMPILER=icpc -D PKG_INTEL=ON -D INTEL_ARCH=cpu -D PKG_KSPACE=ON -D PKG_MOLECULE=ON -D PKG_EXTRA_MOLECULE=ON -D PKG_EXTRA_PAIR=ON -D PKG_PHONON=ON -D PKG_MANYBODY=ON -D BUILD_OMP=yes -D PKG_OPENMP=ON -D CMAKE_CXX_FLAGS=-fopenmp -D CMAKE_EXE_LINKER_FLAGS=-fopenmp -D PKG_GPU=ON -D GPU_API=cuda -D GPU_PREC=double -D GPU_ARCH=sm_60 -D FFT=FFTW3 -D FFT_SINGLE=YES -D FFTW3F_LIBRARY=/path/to/fftw/3.3.10/lib64/libfftw3f.a -D FFTW3F_OMP_LIBRARY=/path/to/fftw/3.3.10/lib64/libfftw3f_omp.a~$ cmake --build .~$ make installPackages are loaded according to needs. Some comments: As stated before, CMAKE_CXX_COMPILER=icx (the new Intel DPC++/C++ compiler) can lead to errors. EXTRA_MOLECULE and EXTRA_PAIR packages are automatically removed during configuration. Edit ‘CMakeCache.txt’ afterwards to reopen them. GPU-related options depend on architecture. See the LAMMPS manual for instructions. When the single-precision FFTW3 lib is used (FFT_SINGLE=YES), the keywords of libs should be FFTW3F_LIBRARY and FFTW3F_OMP_LIBRARY. Otherwise, they are FFTW3_LIBRARY and FFTW3_OMP_LIBRARY. Static libs are strongly recommended for static linking. The code can auto decide whether to launch threaded FFTW3 compilation according to FFTW3_OMP_LIBRARY. Using FFT_FFTW_THREADS is redundant and can lead to an error that the FFTW3 lib supporting OpenMP is not found (even though FFTW3_OMP_LIBRARY is specified).Dynamic buildThe following options enable a dynamic linking:~$ cmake ../cmake --install-prefix /path/to/lammps/23Jun2022/ -D LAMMPS_MACHINE=dym -D CMAKE_CXX_COMPILER=icpc -D PKG_INTEL=ON -D INTEL_ARCH=cpu -D PKG_KSPACE=ON -D PKG_MOLECULE=ON -D PKG_EXTRA_MOLECULE=ON -D PKG_EXTRA_PAIR=ON -D PKG_PHONON=ON -D PKG_MANYBODY=ON -D BUILD_OMP=yes -D PKG_OPENMP=ON -D CMAKE_CXX_FLAGS=-fopenmp -D CMAKE_EXE_LINKER_FLAGS=-fopenmp -D BUILD_SHARED_LIBS=ON -D LAMMPS_EXCEPTIONS=ON -D PKG_PYTHON=ON -D PKG_GPU=ON -D GPU_API=cuda -D GPU_PREC=double -D GPU_ARCH=sm_60 -D FFT=FFTW3 -D FFT_SINGLE=YES -D FFTW3F_LIBRARY=/path/to/fftw/3.3.10/lib64/libfftw3f.so -D FFTW3F_OMP_LIBRARY=/path/to/fftw/3.3.10/lib64/libfftw3f_omp.so~$ cmake --build .~$ make installSome comments: A dynamic build is launched by BUILD_SHARED_LIBS=ON. The PYTHON package is included for integrating with python developing environment, see LAMMPS manual. The LAMMPS_EXCEPTIONS=ON option is to help keep and trace back the potential LAMMPS errors happened within python scripts. Dynamic FFTW3 libs (‘libfftw3f.so’, ‘libfftw3f_omp.so’) are used in this example.Integration with Python developing environmentUse static libsLoading the static builds for simulations and other packages for pre- and post- processing is a rather mature technique, which involves mainly python programming and a moderate amount of Linux command line. This can be achieved by already developed packages such as ASE LAMMPS calculators and PyIron.Enable a object-oriented programmingAn purely object-oriented programming fashion is realized by loading the dynamic lib to Python developing environment, see LAMMPS manual. The following paths should be specified: the dynamic lib file, in ‘/path/to/lammps/23Jun2022/lib64/liblammps_dym.so’ the LAMMPS python module, in ‘/path/to/lammps/23Jun2022/lib/site-packages/lammps’The default lib name for lammps object is ‘liblammps.so’. To correctly import and create the lammps object, the name can be specified by lammps.lammps(name=&#39;dym&#39;), or use the following command:~$ ln -s /path/to/lammps/23Jun2022/lib64/liblammps_dym.so /path/to/lammps/23Jun2022/lib64/liblammps.soTo correctly load the LAMMPS python module, the user can either merge the ‘lib/site-package’ folder with the default ‘site-package’ directory of the conda environment, or export the path to the environmental variable $PYTHONPATH. Alternatively, the path can be added on the top of python scripts, which is recommended:&amp;gt;&amp;gt;&amp;gt; import sys&amp;gt;&amp;gt;&amp;gt; sys.path.append(&#39;/path/to/lammps/23Jun2022/lib/python3.X/site-packages&#39;)&amp;gt;&amp;gt;&amp;gt; import lammpsThe variable ${OMP_NUM_THREADS} can be set if multi-threading is activated in compilation. The default vale is 1, i.e., no shared memory threading:~$ export OMP_NUM_THREADS=2Launch the python environment, use the following commands:&amp;gt;&amp;gt;&amp;gt; import lammps&amp;gt;&amp;gt;&amp;gt; lmp=lammps.lammps()LAMMPS (23 Jun 2022) using 2 OpenMP thread(s) per MPI task&amp;gt;&amp;gt;&amp;gt; exit()A collection of potential problemsWhen loading the dynamic lib, it is probable that an error occurs: OSError: libpython3.10.so.1.0: cannot open shared object file: No such file or directory. Executable linked dynamically does not include the basic python libs, so the path to python libs should be added to ${LD_LIBRARY_PATH}. Auto edition of environmental variables can be realized during activation / deactivation of anaconda environments. Use the following commands to set initialization options and then restart the python environment:~$ mkdir -p ${CONDA_PREFIX}/etc/conda/activate.d~$ touch ${CONDA_PREFIX}/etc/conda/activate.d/env_vars.sh~$ echo &quot;export LD_LIBRARY_PATH=\\&quot;\\${CONDA_PREFIX}/lib:\\${LD_LIBRARY_PATH}\\&quot;&quot; &amp;gt;&amp;gt; ${CONDA_PREFIX}/etc/conda/activate.d/env_vars.sh~$ mkdir -p ${CONDA_PREFIX}/etc/conda/deactivate.d~$ touch ${CONDA_PREFIX}/etc/conda/deactivate.d/env_vars.sh~$ echo &quot;LD_LIBRARY_PATH=\\`echo \\${LD_LIBRARY_PATH//\\&quot;\\${CONDA_PREFIX}/lib:\\&quot;/&#39;&#39;}\\`&quot; &amp;gt;&amp;gt; ${CONDA_PREFIX}/etc/conda/deactivate.d/env_vars.shBy doing so, the ncurses lib from Anaconda seems to cover the default one, which leads to 2 problems. The first one is warnings such as ‘libtinfo.so.6: no version information available message using conda environment’, which is due to the releases of ncurses on the default Anaconda channel lack the version information. This can be solved by reinstalling it from the conda-forge channel:~$ conda install -c conda-forge ncursesThe second one is that it makes the top command, and probably more commands, invalid. But the ps command is effective. If the error occurs, finding an alternative or deactivating the current environment seem to be the only 2 solutions.If the dumping option of video is activated, the path to the ffmpeg (for dumping videos) executable should be exported to ${PATH}, while libpng, zlib and libjpeg remain accessible." }, { "title": "How to use Imperial College Research Data Store (RDS)", "url": "/posts/How-to-use-Imperial-College-Research-Data-Store-(RDS)/", "categories": "Technique, others", "tags": "linux, windows, Imperial RCS, Imperial RDS", "date": "2022-10-05 20:57:04 +0100", "snippet": "In this post, necessary tutorials are collected and the step-by-step guides are provided for setting up connections to Imperial College Research Data Store (RDS) services on Linux (OpenSUSE) and Windows (Windows10 Pro) machines. Connection on OpenSUSE is tested on NHPC101\\@ic.ac.uk on 29 Sept. 2022, and the connection on Win10 Pro is tested on my personal laptop on 5 Oct. 2022. Special thanks to Dr. G. M. for addressing my issues with Windows. Updated 13 Feb. 2024.What is RDS?A comprehensive introduction is in the Wiki page accessible for college users. Several comments are added for explanation. RDS is a cloud disk of which the space can be requested by the principle investigator (PI) of a group only, based on his/her budgets. Students’ access (either editable or read-only) to the certain folder of RDS is provided after being permitted by its admin. RDS has been integrated into Imperial CX1. The rds.imperial.ac.uk/RDS/user/${USER}/home/ folder is the ${HOME} directory of cluster; the rds.imperial.ac.uk/RDS/user/${USER}/ephemeral/ is the ${EPHEMERAL} directory (${USER} is your college username, same for following texts.). See Connect to the Imperial Cluster and Structure and usage of Clusters for more information. Even if you do not have access to any project folder, your own data can still be stored on the 1TB disk space that comes with your HPC resource allocation. The rds.imperial.ac.uk/RDS/user/${USER}/projects folder stores data of specific projects (in the sub-folder of that project) that may be shared around the group. The partition of archives is explained here. Usually live is sufficient for ongoing projects. To examine and manage your RDS project allocations, visit this website. RDS can also be accessed by this webpage. After logging in, click on the ‘File Manager’ tab from the side bar. In the ‘Collection’ box on the top, search for ‘Imperial College London Research Data Store’ to visit folders under your account.Map RDS as a netdiskInstead of visiting your data every time via a web browser, RDS folders can be mapped on your machine as a netdisk, making visiting it as convenient as visiting local disks - as long as you have proper internet connections.On lab servers Open the Dolphin file manager. From the left column, select ‘Remote-Network’. From the panel that appears, click on ‘Shared Folders (SMB)’. Click on ‘smb:’ on the top of the panel and open the address line. In the address line, enter the path to your RDS folder: smb://rds.imperial.ac.uk/RDS/user/${USER}/home (This commands leads to your home directory on CX1). In the popup window, enter your username with the domain, i.e., ${USER}@ic.ac.uk and your college account password.The account management software that comes with OpenSUSE (KDE Wallet) will popup the window with auto-filled credentials every time you access the shared folder. Use KWallet Manager to modify your information.On Windows machines Connect to Imperial VPN. For instructions of setting it up, refer to this step-by-step guide. Note that according to tests on Win10 Pro, connection by Open VPN is not needed. Open the file explorer. Right click on ‘Network’ and select ‘Map Network Drive’. Select any unused letter as the flag. In ‘Folder’, enter: \\\\rds.imperial.ac.uk\\RDS\\user\\${USER} for everything under your name. If you get multiple projects, it is also possible to add paths of subfolders to load them as independent drives. For example, to load the home directory of CX1, you can use: \\\\rds.imperial.ac.uk\\RDS\\user\\${USER}\\home. Click on ‘Finish’ button. If the Internet connection works fine, after several seconds, a Windows Security popup will appear, asking for the college password. If you simply enter your password, although correctly, the ‘invalid password’ error will appear. The reason is that RDS requires a login domain, which is not provided with the current username. Select ‘More choices/User a different account’. In ‘Username’, enter: ${USER}@ic.ac.uk. Then enter the password in the next box." }, { "title": "Set Up a Remote Jupyter Server", "url": "/posts/Launch-Jupyter-Notebook-from-a-Remote-Server/", "categories": "Technique, programming", "tags": "Anaconda3, python, linux, windows", "date": "2022-08-10 18:11:07 +0100", "snippet": "In this post the method to launch the Jupyter service remotely is introduced, i.e., set up a remote Jupyter server. Note that is different from setting up a remote desktop connection, where the image on the monitor is transferred in real-time and a higher data stream is required. In the current case, the remote server is set as a ‘Jupyter Notebook server’, so the notebook app is launched locally in the browser, but the user can still have access to the environments and files on the remote server. Updated tests on Windows 10, NHPC101 and ARCHER2, Mar. 09, 23. Revised on Feb. 25, 24.Project JupyterProject Jupyter is an open-source, cross-platform programming environment which provides hierarchical services for multiple programming languages (with the optimal support to python and R, of course). To deploy Jupyter service framework on a server, Jupyter Core and Jupyter Server are needed.Jupyter Core and Jupyter Server cannot do any specific job except providing interactive programming environment and establishing communications to specific applications. When the server is launched, its configuration file is applied to other applications, unless a specific configuration file is defined elsewhere for that specific application.Jupyter Notebook provides an interactive programming environment by calling the corresponding kernel and a basic file explorer. Markdown and Latex equations are provided as well, making it is useful for writing a script or developing a workflow. Jupyter Lab provides a more comprehensive integrated developing environment (IDE) for a single user, including Notebook, console, terminal, file explorer and text editor. Obvious advantages of Jupyter Lab include light-weight, highly extendable and customizable. The thing that I am not pretty happy with is that it, so far, has poor support of ssh and http, and prohibits downloading folders. Jupyter Hub manages IDE for multiple users. It can both deploy users’ local environment set-ups and provide the default environment for all users. It is also the recommended way to call Jupyter Services on Imperial RCS.Jupyter Hub is set in this post for personal use.Configure Jupyter ServerThe recommended way to install Jupyter services is using conda package and environment manager, such as Anaconda or Mamba. The essentials of Jupyter Hub and Server is suggested to be installed in the ‘base’ (default) environment, while the interpreter and compiler of programming languages are installed in individual environments. This avoids potential conflicts in dependencies and the (in)famous ‘Solving Environment’ issue of conda. The following command installs Jupyter Core, Server, Lab, Notebook from the channel ‘conda-forge’ (as suggested):(base)$ conda install jupyter -c conda-forgeGenerate a configuration fileA configuration file for Server is needed, which is not automatically generated when graphical user interface is not available, such as when setting up the server on clusters. To generate the configuration file, use the following command:(base)$ jupyter server --generate-configThen by default, the file is generated as ${HOME}/.jupyter/jupyter_server_config.py. Refer to the messages in command line.Generate passwordA password is (by default) needed for servers. There are 2 ways to generate the password: Automatic generation: By default, the hashed password can be found in ${HOME}/.jupyter/jupyter_server_config.json.(base)$ jupyter server password Manually generate a hashed password. Launch the conda environment that requires a Jupyter Server. In command line, type python3 to enter the interactive python environment, then:&amp;gt;&amp;gt;&amp;gt; from notebook.auth import passwd&amp;gt;&amp;gt;&amp;gt; passwd()&amp;gt;&amp;gt;&amp;gt; exit()Then copy the generated token, the one with single quotes.Edit configuration fileOpen the configuration file ${HOME}/.jupyter/jupyter_server_config.py. Find and uncomment the following options:c.ServerApp.allow_password_change = True # Allow the password to be changed at login for the Jupyter serverc.ServerApp.allow_remote_access = True # Allow remote access to the serverc.ServerApp.ip = &#39;*&#39; # Viable for all ip addressesc.ServerApp.password = u&#39;argon2:$argon2id$v=......&#39; # The hashed passwordc.ServerApp.password_required = False # If you do not want to enter password everytime you loginc.ServerApp.port = 1008 # Port number, can be any number, as long as it is unoccupied.c.ServerApp.root_dir = &#39;/home/username&#39; # Root directory of Jupyter Server, the directory from which the Jupyter service startsIf you are sure that you will not use graphic interface of the server, you can set --no-browser as the default option in the configuration file to prevent the server to launch the browser locally:c.ServerApp.open_browser = FalseIn practice, it is found that leaving the hashed password in jupyter_server_config.json will lead to invalid token error for the first-time login. So it is strongly recommended to copy the hashed password into the configuration file however the user generated it. And the user should be noted that for the first-time login, the password is required even though c.ServerApp.password_required = False.For the port number, if you are not sure whether it is occupied by other processes, after the file is configured, in command line, type jupyter server and check messages on the screen for the available port number. It is suggested to update the c.NotebookApp.port value to avoid future tests.Setup environmentsAs mentioned before, the actual programming environment is suggested to be isolated from Jupyter Service and other programming environments. After installing the packages from conda in a new environment, the kernel should be added to Jupyter in ‘base’ environment. Here lists some programming environments that I used.Useful commends conda create -n &amp;lt;name&amp;gt; Creates a new conda environment. conda env list Lists all the conda environments. conda remove -n &amp;lt;name&amp;gt; --all Completely remove an environment. jupyter kernelspec install --user &amp;lt;path&amp;gt; Configure Jupyter kernel using the files in the path. jupyter kernelspec list List the available kernels. jupyter kernelspec uninstall &amp;lt;name&amp;gt; Remove a kernel.PythonJupyter has the optimal support to python as it is where Jupyter was from. Use the following command to get a python3.9 environment and add kernel to Jupyter:(base)$ conda create -n python39 python=3.9 # Get an env called &#39;python39&#39;(base)$ conda activate python39(python39)$ conda install ipykernel(python39)$ ipython kernel install --user --name=python39 # Add the kernel &#39;python39&#39; for the current user(python39)$ conda deactivateThen launch Jupyter Hub (see the next section), the kernel ‘python39’ is available on the start-up panel.C++A popular implementation is Xeus-Cling. ‘Xeus’ is the protocol of Jupyter to implement programming languages and ‘Cling’ is C++ interpreter which enables interactive developing and quick compilation (probably not optimal) of C++ codes. It takes some time to install and compile Cling.(base)$ conda create -n cpp # Get an env called &#39;cpp&#39;(base)$ conda activate cpp(cpp)$ conda install xeus-cling -c conda-forge(cpp)$ conda deactivateAfter installation, go back to ‘base’ environment and configure kernel by the kernel setups that come with Xeus-Cling:(base)$ jupyter kernelspec install --user path/to/anaconda/envs/cpp/share/jupyter/kernels/xcpp11(base)$ jupyter kernelspec install --user path/to/anaconda/envs/cpp/share/jupyter/kernels/xcpp14(base)$ jupyter kernelspec install --user path/to/anaconda/envs/cpp/share/jupyter/kernels/xcpp17Then launch Jupyter Hub (see the next section), kernels ‘xcpp11’, ‘xcpp14’ and ‘xcpp17’ are available on the start-up panel.FORTRANThings with Fortran is always tricky as it is not as popular. The optimal solution that I found is LFrotran which also follows Xeus protocol. An alternative is the minimalist’s jupyter-fortran-kernel.(base)$ conda create -n fortran # Get an env called &#39;fortran&#39;(base)$ conda activate fortran(fortran)$ conda install lfortran -c conda-forge(fortran)$ conda deactivateSimilarly, config fortran kernel in ‘base’ environment:(base)$ jupyter kernelspec install --user path/to/anaconda/envs/fortran/share/jupyter/kernels/fortranThen launch Jupyter Hub (see the next section), kernel ‘fortran’ is available on the start-up panel.Connect to the serverNow the server has already been set up. Use the following command to connect to the server:~$ ssh -L localhost:1009:localhost:1008 username@serverip-L option specifies the remote (1008) and local (1009) port numbers. The port numbers can be any ones that are not occupied by remote/local processes. The remote one is suggested to be the default port number of Jupyter services. Alternatively, the user can specify the Jupyter Service port when launching it (see below), but that number should be consistent with the remote port specified during logging in.Then the connection is set up as usual. Using the following command to launch, for example, Jupyter Notebook:(base)$ nohup jupyter notebook --no-browser --port=1008 &amp;gt; /dev/null 2&amp;gt;&amp;amp;1 &amp;amp;nohup hangs up the process in the background to avoid occupying the command line and the normal + error output is redirected to nowhere (/dev/null). --no-browser is to prevent the application to open the browser of the server, not needed if c.NotebookApp.open_browser = False. --port specifies the remote port, if it is not the default one. Then open the browser in the local machine. Enter the address with local port: http://localhost:1009. Enter the password (not the token) to use notebook. To shut down Jupyter Notebook, kill the process (kill -9 + PID) by PID. To get process ID, use ps -ef | grep &#39;jupyter&#39;.Alternatively, when using Jupyter Hub, the nohup command is unnecessary as the Hub provides access to terminal. However, some key-bindings are covered by Hub, such as ctrl+c is copy if the text is highlighted, while in Linux it is escaping the current command.(base)$ jupyter lab --no-browser --port=1008" }, { "title": "Compile ONETEP and run quality tests", "url": "/posts/Compile-ONETEP-and-run-quality-tests/", "categories": "Technique, Parallel Computing", "tags": "ONETEP, linux", "date": "2022-06-20 17:34:38 +0100", "snippet": "This post summarizes how to successfully compile ONETEP and run quality tests. The available version of ONETEP is v6.1.9, released on Jun. 2, 2022. Used compilers + fftw + libraries include: For Imperial CX1 and lab server(OpenSUSE Leap 15.3): Intel OneAPI tool kit 2022.1.2 versions - ifort 2022, FFTW3 as the wrapper of Intel MKL, ScalAPACK, OpenMP. For ARCHER2: Cray versions of Fortran compiler v12.0.3, mpich v8.1.4 and fftw3 v3.8.11. With OpenMP and ScaLAPACK.Tested from Jun. 19 to Jun. 20, 2022.General introductionsONETEP, the Order-N Electronic Total Energy Package, is a linear-scaling periodic DFT package based on orthogonal generalized Wannier function basis sets. Its basis set is equivalent to planar-wave BSs so is free from the famous basis set superposition error(BSSE) and has tunable completeness by cut-off energy. Meanwhile, it also has attributes of atomic orbitals like relative small basis sets and therefore suitable for large system. Its most important feature is that its computational load strictly linear-scales with the system size.Compile ONETEP on ARCHER2Compiling ONETEP on supercomputers is relatively easy thanks to the sensible developers and cluster maintenance team. Detailed institutions can be found in the folder ‘hpc_resources/’. The pre-compiled version is available as an environmental module on ARCHER2, to which the access can be requested via your ARCHER2 account at SAFE. No modification is recommended unless you are an expert user (in which case you won’t refer to this page).Compile ONETEP with Intel OneAPIMulti-process parallelizationGet Intel OneAPI 2022.1.2.184 base version and HPC version:~$ wget https://registrationcenter-download.intel.com/akdlm/irc_nas/18487/l_BaseKit_p_2022.1.2.146_offline.sh~$ wget https://registrationcenter-download.intel.com/akdlm/irc_nas/18479/l_HPCKit_p_2022.1.2.117_offline.shAccording to the recommendation in the file ‘INSTALL’, the threaded FFTW3 wrapper of MKL is recommended (-DMKL_FFTW3) instead of a standalone FFTW3 lib to make sure the compiled version is thread-safe (Of course a standalone FFTW3 is fine if ONETEP is not compiled for multi-threading). To do this, the path to ‘mkl_service.mod’ should be given according to the CPU architecture and the length of MKL integer (see below).The libs needed to be linked can be specified in keyword LIBS. It’s tricky to set proper flags for MKL. Fortunately Intel link line advisor webpage or attached app can offer suggested values according to the environment.Versions of compiler and Linux distributions have been stated above. The compilation file for NHPC101 and Imperial CX1:F90 = mpiifortFFLAGS = -DMPI -I&quot;${MKLROOT}/include&quot; -DMKL_FFTW3 -I&quot;${MKLROOT}/include/intel64/lp64/mkl_service.mod&quot; -qmkl=parallel -DSCALAPACK -diag-disable 8290,8291,7712,5462 LIBS = -L${MKLROOT}/lib/intel64 -lmkl_scalapack_lp64 -lmkl_cdft_core -lmkl_intel_lp64 -lmkl_sequential -lmkl_core -lmkl_blacs_intelmpi_lp64 -lpthread -lm -ldlOPTFLAGS = -O3 -xhostDEBUGFLAGS = -traceback -check all -traceback -warn all -DTRACE -DDEBUG_ARRAYSCOMPILER = INTEL-ifort-on-LINUXNote that NHPC101 has limited stack size(8192). Use the following command every time before launching a calculation:~$ ulimit -s unlimitedMulti-threading parallelizationThe multi-threading version of compilation file for NHPC101 and Imperial CX1:F90 = mpiifortFFLAGS = -DMPI -I&quot;${MKLROOT}/include&quot; -DMKL_FFTW3 -I&quot;${MKLROOT}/include/intel64/lp64/mkl_service.mod&quot; -DParallelFFT -qmkl=parallel -DSCALAPACK -diag-disable 8290,8291,7712,5462 -qopenmp -DDEFAULT_THREADS=2LIBS = -L${MKLROOT}/lib/intel64 -lmkl_scalapack_lp64 -lmkl_cdft_core -lmkl_blacs_intelmpi_lp64 -liomp5 -lpthread -lm -ldlOPTFLAGS = -O3 -xhostDEBUGFLAGS = -traceback -check all -traceback -warn all -DTRACE -DDEBUG_ARRAYSCOMPILER = INTEL-ifort-on-LINUX-DDEFAULT_THREADS=2 set the default threads_max and threads_num_fftboxes threading of each process to be 2. Using the following command before any calculation, the number of threading will cover the default value and increases to 4.~$ export OMP_NUM_THREADS=4Multi-threading needs a separate setting of stack size. Use the following command before any calculation:~$ export OMP_STACKSIZE=64MNOTE Compilation on CX1 does not support the option -xhost, which forces the use of the highest instruction set available, due to unknown reasons. Compilation is killed by signal when interpreting the object file, ‘function_basis_mod.o’, of the script ‘function_basis_mod.F90’. The current compilation on CX1 is not compatible with test scripts on throughput nodes. In the best case, the job got stuck after printing the input information. Test scripts works well on login nodes." }, { "title": "Structure and usage of clusters", "url": "/posts/Structure-and-usage-of-clusters/", "categories": "Technique, Parallel Computing", "tags": "cluster, Imperial RCS, ARCHER2, regular inspection, linux", "date": "2022-04-06 16:59:03 +0100", "snippet": "This page is adapted from my Crystal Growth project notebook with added contents, which was written between Feb. and Mar. 2022 and shared within the group for induction and training proposes. Both this page and the notebook are under regular inspection, but their contents are not synced.Divide a job: Nodes, Processors and ThreadsNode: A bunch of CPUs and probably with GPUs / coprocessors for acceleration. Memory and input files are shared by processors in the same node, so a node can be considered as an independent computer. The communication between nodes are achieved by ultra-fast network, which is the bottleneck of modern clusters.Processor: The unit to deal with a ‘process’, also known as ‘central processing unit’, or CPU. Processors in the same node communicate via shared memory.Thread: Subdivision of a process. Multiple threads in the same process share the resources allocated to the CPU.The figure below illustrates the hierarchy of node, processor, and thread:Multiple processes vs multiple threadsFrom the figure above, it is not difficult to distinguish the differences between a ‘process’ and a ‘thread’: process is the smallest unit for resource allocation; thread is part of a process. The idea of ‘thread’ is introduced to address the huge difference in the speed of CPU and RAM. CPU is always several orders of magnitude faster than RAM, so typically the bottleneck of a process is loading the required environment from RAM, rather than computations in CPU. By using multiple threads in the same process, various branches of the same program can be executed simultaneously. Therefore, the shared environmental requirements doesn’t need to be read from RAM for multiple times, and the loading time for threads is much smaller than for processes.However, multithreading is not always advantageous. A technical prerequisite is that the program should be developed for multithread proposes. Python, for example, is a pseudo-multithread language, while Java is a real one. Sometimes multithreading can lead to catastrophic results. Since threads share the same resource allocation (CPU, RAM, I/O, etc.), when a thread fails, the whole process fails as well. Comparatively, in multiple processes, other processes will be protected if a process fails.In practice, users can either run each process in serial (i.e., number of threads = 1), or in parallel (i.e., number of threads &amp;gt; 1) on clusters. However, the former is recommended, because of more secured resource managements. The latter is not advantageous. Besides the problem mentioned above, it might lead to problems such as memory leak when running programs either: not developed for multithreading / requires improper packages (See the famous libfabric issue on ARCHER2) - common problems of scientific computing packages &amp;amp; their users. :-)More nodes vs more CPUsWhen the allocated memory permits, from my experience, using more CPUs/processes per node is usually a better idea, considering that all nodes have independent memory space and the inter-node communications are achieved by wired networks. It almost always takes longer to coordinate nodes than to coordinate processors within the same node.The internal coordinator: What is MPIMessage passing interface, or MPI, is a standard for communicating and transferring data between nodes and therefore distributed memories. It is utilized via MPI libraries. The most popular implementations include: MPICH - an open-source library; Intel MPI - a popular implementation of MPICH especially optimised for Intel CPUs; OpenMPI - an open-source library; OpenMP - Not MPI; parallelization based on shared memory, so only implemented in a single node; can be used for multithreading;In practice, a hybrid parallelization combining MPI and OpenMP to run multithread jobs on cluster is allowed, though sometimes not recommended. The first process (probably not a node or a processor) is usually allocated for I/O, and the rest is used for parallel computing.So far, MPI only supports C/C++ and FORTRAN, which explains why all parallel computing software is based on these languages. To launch an executable in parallel, one should specify: mpiexec or mpirun.Technical details about how MPI is implemented is too advanced for typical computational chemists / solid state physicists, which is a specific, completely different research area, so they are not covered in this page.Distribute files: The role of job submission scriptsAs mentioned in previous sections, memories are distributed to nodes. Considering the inefficiency of inter-node communication, it is unpractical to frequently transfer files across nodes. In practice, required input files are duplicated, or synced, to all the nodes before any calculation. During the calculation, data is transferred from computing nodes between the I/O node.Although such sync is automatic for almost any modern cluster, it is safer to specify that when developing job submission scripts:~$ ssh ${NODEADDRESS} &quot;${COMMAND}&quot;Secure your storage: Work directory and home directoryAll the modern clusters have separate disk spaces for differently proposes, namely, work directory and home directory. This originates again from the famous speed difference between CPU and RAM/ROM. 2 distinctly kinds of disks are used respectively to improve the overall efficiency and secure important data: For work directory, large, high-frequency disks are used. Data stored in work directory is usually not backed up, and in some cases, will be automatically cleaned after a fixed time length. For home directory, mechanical disks with slower read/write frequency but better robustness are used. Usually files in home space are backed up.For large clusters like ARCHER2, the work directory and the home directory are completely separated, i.e., directory is only viable by login nodes; work directory is viable by both job and login nodes. Job submission in home directory is prohibited.For more flexible, medium-sized clusters like Imperial CX1, submitting jobs in home directory and visiting home directory by job nodes are allowed, yet storing temporary files during calculation in home directory is still not recommended because of the potential influence on other files and the reduced overall efficiency. Work and home directories can be called with the following environmental variables:${EPHEMERAL} - Work directory. Data will be cleaned over 30 days.${HOME} - Home directory.Setup your environment: What does an application need?ExecutableThe binary executable should, theoretically, all be stored in \\usr\\bin. This never happens in practice, unless you are a fanatical fundamentalist of the early Linux releases. To guide your system to the desired executable, you can either laboriously type its absolute path every time you need it or add the path to the environmental variable:~$ export PATH=${PATH}:path_to_binRunning any executable in parallel requires mpi to coordinate all the processes/threads. The path to mpi executable is also required. Besides, many scientific codes require other specific environmental variables such as linear algebra packages. Read their documentations for further information.lib/a/o filesWhen writing a script, you might need some extra packages to do more complex jobs. Those packages are developed by experts in computer science and can be called by a line of code. The same thing happens when people were developing applications like CRYSTAL and ONETEP.However, scientific computing codes are usually distributed in the form of source code. Source codes in FORTRAN/C/C++ need be compiled into a binary executable. There are 2 options during compiling: Include the whole package as long as one of its functions is called, also known as a ‘static lib’. Only include a ‘table of contents’ when compiling, also known as ‘dynamic lib’. The packages needed are separately stored in ‘dll/so’ files, making it possible for multiple applications sharing the same lib.Details about compilation are beyond the scope of this post. Maybe I will make another post to discuss them, when I am more confident with this topic. The thing is: when running a dynamically linked application, information should be given to help the code find the libs needed. This can be specified by:~$ export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:path_to_lib`For statically linked applications, usually you need not worry about it - but the volume of the compiled executable might make you feel wonder whether there is an alternative way.ConflictsImproper previous settings may lead to a wrong application, or a wrong version, if multiple applications with similar functions are installed in the system, such as Intel compiler and GCC, OpenMPI and MPICH - a common phenomenon for shared computing resources. To avoid this, the path to the undesired application or lib should be removed from the environmental variables.Environmental ModulesEnvironmental modules is a popular software managing the necessary environmental setups and conflicts for each application. It can easily add or erase the environmental variables by commands module load or module rm, and modulefiles written in Tool Command Language (TCL). The default directory of modulefiles is given in the environmental variable ${MODULEPATH}, but files in other directories can also be loaded by their absolute path.Both Imperial CX1 and ARCHER2 adopt this application, which pre-compiled applications offered.The external coordinator: What is a batch systemAlways bear in mind that the computational resources are limited, so you need to acquire reasonable resources for your job. Besides, the cluster also needs to calculate your budget, coordinate jobs submitted by various users, and make the best of available resources. When job is running, maybe you also want to check its status. All of this are fulfilled by batch systems.In practice, a Linux shell script is needed. Parameters of the batch system of are set in the commented lines at the top of the file. After the user submit the script to batch system, the system will: Examine the parameters Allocate and coordinate the requested resources Set up the environments, such as environmental variables, package dependency, and sync the same setting to all nodes Launch a parallel calculation - see mpi part Post-processNote that a ‘walltime’ is usually required for a batch job, i.e., the maximum allowed time for the running job. The job will be ‘killed’, or suspended, when the time exceeds the walltime, and the rest part of the script will not be executed. timeout command can be used to set another walltime for a specific command.Common batch systems include PBS, which involves different releases, and Slurm. For Imperial cluster CX1 and MMM Hub Young (managed by UCL), PBS system is implemented; for ARCHER2 and Tianhe-2 LvLiang(天河二号-吕梁), Slurm is implemented. Tutorials of batch systems are not covered here, since they are highly machine-dependent - usually modifications are made to enhance the efficiency. Refer to the specific user documentations for more information.How to run a job in parallel: Things to considerSuccessfully setting and submitting a batch job script symbolizes that you do not need this tutorial any more. Before being able to do that, some considerations might be important: How large is my system? Is it efficient to use the resources I requested(Note that it is not a linear-scaling problem… Refer to this test on CRYSTAL17)? To which queue should I submit my job? Is it too long/not applicable/not available? Is it safe to use multi-threading? Is it memory,GPU etc. demanding? Roughly how long will it take? What is my budget code? Do I have enough resources? Which MPI release version is my code compatible with? Should I load a module or set variables? Any other specific environmental setups does my code need? Do I have any post-processing script after MPI part is finished? How long does it take?" }, { "title": "Common symbol names in English", "url": "/posts/Common-symbol-names-in-English/", "categories": "Research, English", "tags": "academic English", "date": "2022-04-01 11:48:44 +0100", "snippet": "The biggest difficulty I met when mentoring master students and doing TA is not to actually fix bugs, but to guide the student to enter a specific command - I never learnt the names of common symbols for either programming or writing in any English class, which is a terrible oversight.Here I collected the English name list of common symbols for reference.Class 1: Symbols on keyboard SYMBOLS NAMES ~ Tilde ` Backtick, back quote ¬ Negation (symbol) £ Pound sign, Pound stering symbol $ Dollar sign % Percent sign ^ Caret &amp;amp; Ampersand * Asterisk () Parenthesis - Hyphen [] Square brackets {} Curly brackets, Braces, Squiggly brackets &amp;lt;&amp;gt; Angle brackets &amp;gt;, &amp;lt; Greater-than, Less-than signs », « Right, Left shift : Colon ; Semicolon . Full stop, Full stop punction , Comma @ At, At sign # Number sign, Hash ’’ (single) Quotation marks, Quotes ”” (double) Quotation marks, Quotes ! Exclamation mark ? Question mark / Slash \\ Backslash | Viertical bar Class 2: Escape characters SYMBOLS NAMES \\a Alert, Bell \\b Backspace \\e Escape \\f Form feed \\n New line \\r Carrage return \\s Space \\t Tab \\v Vertical tab Class 3: Greek alphabet UPPER, LOWER CASE NAME $A, \\alpha$ Alpha $B, \\beta$ Beta $\\Gamma, \\gamma$ Gamma $\\Delta, \\delta$ Delta $E, \\epsilon$ Epsilon $Z, \\zeta$ Zeta $H, \\eta$ Eta $\\Theta, \\theta$ Theta $I, \\iota$ Iota $K, \\kappa$ Kappa $\\Lambda, \\lambda$ Lambda $M, \\mu$ Mu $N, \\nu$ Nu $\\Xi, \\xi$ Xi $O, o$ Omicron $\\Pi, \\pi$ Pi $R, \\rho$ Rho $\\Sigma, \\sigma$ Sigma $T, \\tau$ Tau $\\Upsilon, \\upsilon$ Upsilon $\\Phi, \\phi$ Phi $X, \\chi$ Chi $\\Psi, \\psi$ Psi $\\Omega, \\omega$ Omega " }, { "title": "Install and configure themes for Jupyter Notebook", "url": "/posts/Jupyter-Themes/", "categories": "Technique, programming", "tags": "Anaconda3, python", "date": "2022-04-01 00:21:09 +0100", "snippet": "Jupyter Notebook is a web-based, interactive python developing environment which has been integrated into Anaconda 3. However, it is sometimes annoying especially for long-time users that it has no dark mode. Although it is possible by setting up the forced dark mode in chrome, the cursor is kept black, making it difficult to be found.Jupyter Themes is a GitHub project to develop and set themes for Jupyter Notebook. Tested on Mar. 30-2022.InstallTo install Jupyter Themes, activate the corresponding environment, and use the command:~$ pip install jupyterthemesNote: conda install command does not work.UsageFor detailed usage, please refer to the Readme page of Jupyter Themes project. Here is listed my settings for future reference:~$ !jt -t monokai -f dejavu -fs 11 -nfs 10 -T -N -kl -lineh 120Use Jupyter Notebook to run setups, then relaunch it to see changes." }, { "title": "Linux bash script - variables, command outputs, and determine statements", "url": "/posts/Linux-bash-script-variables,-command-outputs,-and-determine-statements/", "categories": "Technique, programming", "tags": "linux, job scheduler", "date": "2022-03-31 16:21:30 +0100", "snippet": "No update for so long - I have been busy with some technical work in the group. The masters students I mentor are using LAMMPS for classical molecular dynamics simulations, with which neither my supervisor nor myself have much experience. It is a delicate job to compile parallel LAMMPS package and design job submission scripts on Imperial cluster, or Imperial RCS. Luckily it is fruitful. By doing so my knowledge of both Linux bash programming, which I haven’t actually engaged in for more than one year, and the structure of the cluster has increased a lot.I will probably update my thinking in the following days, as long as time permits. I still have 2 unfinished posts, the stone curving of Southern Dynasties and parameter lists for Grimme’s DFT-D3 method, which has been delayed for so long. Hopefully I’ll address them in this weekend.VariablesVariables should be named as the combination of numbers, letters, and underscore.Special variablesHere is the list of special variables and their meanings, which should not be occupied when programming. VARIABLES MEANINGS $0 Name + path of the current script $n n is an integer &amp;gt; 0. External variables, entered after the script name before executing $# The number of external variables $* All the external variables, “$1”, “$2”, … ”$*” All the external variables as a single variable, “$1 $2 …” $@, “$@” Same to $*, all the external variables, “$1”, “$2”, … $? Exit status of the last command. Successful, =0; Failed, &amp;gt;0 $$ PID of the current process Environmental variablesThe specific definition of environmental variables depend on the specific environment. Here the important environmental variables of Imperial cluster / PBS job scheduler and ARCHER2 / slurm job scheduler are listed for reference.Imperial cluster / PBS VARIABLES MEANINGS ${HOME} Home directory, /rds/general/user/${USER}/home/ ${USER} User name ${TMP} Temporary (work) directory, /rds/general/ephemeral/user/${USER}/ephemeral ${PBS_JOBID} ID of the current PBS job ${PBS_NODEFILE} The list of nodes currently running the PBS job ARCHER2 / slurm VARIABLES MEANINGS ${HOME} Home directory, /rds/general/user/${USER}/home/ ${USER} User name Note There is no available environmental variable to obtain the ID of an slurm job. To do that, use the command below: JOBID=`sacct -u ${USER} -n -X --format jobid --name jobname.slurm --state r`JOBID=`echo ${JOBID} | rev | cut -d&#39; &#39; -f1 | rev` Variable operationsList variables are defined as (elem1 elem2 ...). Common operations for a list variable ${LIST}: OPERATIONS MEANINGS ${LIST}[n] n &amp;gt;= 0, the nth element of ${LIST} ${LIST} The first element of ${LIST}, ${LIST}[0] ${LIST}[@], ${LIST}[*] All the elements of ${LIST} ${#LIST}[@] The length ${LIST} String variables can be truncated from a specified character or a specified index. Taking link=&#39;spica-vir.github.io&#39; as an example: OPERATIONS MEANINGS ${link%.*} Cut the right most ‘.’ and the content on its right, ${link%.*}=spica-vir.github ${link%%.*} Cut the left most ‘.’ and the content on its right, ${link%%.*}=spica-vir ${link#*.} Cut the left most ‘.’ and the content on its left, ${link#*.}=github.io ${link##*.} Cut the right most ‘.’ and the content on its left, ${link##*.}=io ${link: 3:6} Return to the string with indices 3~6, including 2 ends, ${link: 3:6}=ca-v ${link: 6} Return to the string starting from the index 6, ${link: 6}=vir.github.io ${link: -6} Return to the string of the last 6 characters, ${link: -6}=hub.io Command outputsThe output of commands can be redirected using the symbols listed below: SYMBOLS MEANINGS 0 Standard input 1 Standard output 2 Standard error command &amp;gt; file Redirect the standard output of ‘command’ to a newly created ‘file’ command » file Redirect the standard output of ‘command’ to the end of ‘file’. If ‘file’ does not exist, create it command &amp;gt;&amp;amp; file, command &amp;amp;&amp;gt; file Redirect the standard output and standard error of ‘command’ to a newly created ‘file’ 2&amp;gt;&amp;amp;1 Copy the behavior of standard output and use it for standard error Analysis:# Command 1command &amp;gt; file.out 2&amp;gt;&amp;amp;1# Command 2command 2&amp;gt;&amp;amp;1 &amp;gt; file.out Command 1: Standard output redirected to ‘file.out’; Copied to standard error; Standard error redirected to ‘file.out’. —&amp;gt; Output and error printed in ‘file.out’. Command 2: Standard output by default printed on screen; Copied to standard error; Standard output redirected to ‘file.out’. —&amp;gt; Output printed in ‘file.out’, error printed on screen.Determine statementsDetermine statements are important for both ‘if’ sentences and ‘while’ loops. The differences between statements acting on variables / files, or numbers / strings should be noticed.For files and directories OPERATORS MEANINGS -e File / directory exists, True -s File / directory not empty, True -d Is a directory, True -f Is a regular file, True -h Is a soft link, True -r Readable, True -w Writable, True -x Executable, True For variables OPERATORS MEANINGS ${variable} ${variable} exists, True -z Variable is empty, True For stringsFor string comparison, in case of spaces, adding “” to protect variables is recommended. Besides, == is preferred to -eq due to the same reason. OPERATOR MEANING ”${string_1}” == *”${string_2}”* If ${string_1} contains sub-string ${string_2}, True For numbersFor integer comparison, either -eq formats or == formats are acceptable. But to compare float numbers, bc command should be used: COMMAND MEANING $(echo “$a==$b” | bc) == 1 If float $a equals float $b, True Note bc command returns an integer variable, and it cannot be used as determine statements, otherwise the statement can only tell whether the specific variable is empty." }, { "title": "南京丹阳南朝石刻列表与GPS坐标", "url": "/posts/%E5%8D%97%E4%BA%AC%E4%B8%B9%E9%98%B3%E5%8D%97%E6%9C%9D%E7%9F%B3%E5%88%BB%E5%88%97%E8%A1%A8%E4%B8%8E%E5%9D%90%E6%A0%87/", "categories": "Interest, History", "tags": "南朝, humanities", "date": "2022-02-13 16:18:43 +0000", "snippet": "本文是我高中到大学时（2014-2018）针对南京、丹阳两地南朝陵墓石刻进行的一些走访调查的总结。当时写过一系列的小文章聊以自娱，但是大学之后因为偷懒而不再更新了。况且秦吴绝国，2016年以后负笈求学，走访古迹变得不再容易，只有寒假回家时能零星走访几处。时过境迁，文字图像记录都不再准确，曾经的小文章就不放在这里误导读者了。唯有石刻本身的样貌和坐标不会改变，因此在这里列出以供参考，同时也是对过去的一点小爱好的纪念。古迹名为南朝石刻，实际上以南朝梁石刻为主。得益于武帝早期清明的政局和其本人超长的在位时间，此时也是南朝社会、经济的鼎盛时期。囿于传统对四六文、宫体文学创作的偏见，南梁在文化上似略逊于南齐永明年间，但萧昭明《文选》，徐东海《玉台新咏》足以奠定梁朝独一无二的文学地位，遑论上承建安永明，下启四杰李杜的庾子山。回到文物本身，目前看来，现存所有明确知晓墓主的王侯墓石刻均属梁朝。同时，也仅有梁朝陵墓完整保存了其形制，石兽、华表、石碑的摆放明确且一致。就其它朝而言，仅有帝王陵前石兽得以幸免，不知是形制有变还是纯属巧合。总的来说，帝王陵前石兽均为一只独角麒麟与一只两角天禄相对，而各朝均各有特点，可以从体态、纹饰、爪上指的数量进行分辨。王侯墓前，则以一对无角的辟邪作为石兽。刘宋一朝仅有武帝初宁陵孤证，齐梁两朝石兽则存世颇多，各有千秋。其中齐代石兽体态多修长灵动，纹饰多华美繁琐，而梁代则以体量和整体气势取胜。陈朝仅有武帝万安与文帝永宁两处疑陵，且作风绝不相类，其中永宁陵几乎可以断定是梁陵。由于是国家重点文物保护单位，不能迁移保护，南朝石刻多位居荒郊野外，田间地头。既无便捷的公共交通，又无周全的保存措施。对于南京的多处石刻，我有幸在四年间见证了道路由艰险到宽阔，保护措施从无到有的历程。在此谨向所有为我走访提供便利的人，所有致力于更好地保护这些文物古迹的人致以最真诚的敬意。一些有价值的参考资料： 石仪天下的新浪博客（已停更，首页可以看到公众号链接），http://blog.sina.com.cn/u/1797941727 朱偰, 建康兰陵六朝陵墓图考 朱偰, 金陵古迹名胜影集 沈从文，狮子艺术 洪峰，天禄辟邪源流探析，南京师范大学硕士学位论文，2010 南朝神韵，南京博物院《东南文化》期刊文章合订本由于手头没有纸质资料，一些参考全凭记忆和网络检索，名称可能不太准确。以后有机会再修改。南京栖霞-甘家巷南京市栖霞区甘家巷村、金陵石化南京炼油厂职工生活区与南象山一带分布有多处梁高级贵族墓葬，多为梁武帝萧衍的兄弟辈及其嫡长子。此外南象山有一帝陵规格墓葬。陵墓的分布如下图所示。图中梁武帝兄弟辈墓葬神道方向用红色虚线标出，子侄辈墓葬用绿色虚线标出。箭头自神道口石兽指向墓室方向。未标箭头者则是严格根据地面遗存无法判断的。事实上桂阳简王萧融墓与陈文帝陈蒨永宁陵都已发掘并有发掘报告存世，墓室方位不难确定，只是目前我无处获取资料。而鄱阳忠烈王萧憺墓方位几乎不用怀疑是与其兄始兴忠武王萧恢墓一致的。南朝梁神道石刻的摆放遵循一定的规律，如下图所示：栖霞甘家巷一带的南朝墓葬规格高、保存完好，几乎是研究南朝家族墓葬制度的理想案例。从这张卫星图中不难看出有关专家们总结出的特点：家族丛葬，等级森严，同辈神道平行，子侄辈神道沿父辈神道开枝散叶。若按前人总结的以东为尊的惯例来观察，排行第五的萧融墓在起首，随后是第七的安成康王萧秀墓，而后是紧邻的第十萧憺与第九萧恢墓，排在末尾的则是虽受梁武帝敬重，却不幸是其堂兄弟的吴平忠侯萧景墓。作为儿子，新渝宽侯萧暎墓的神道方向准确地与其父亲萧憺的神道相交。注意萧暎墓仅存石华表，神道口石兽的位置应当更加贴近萧憺墓的神道。从这一规律出发，永宁陵的墓主身份就显得颇为可疑——神道居东且与梁诸王墓神道几乎平行。2015年左右的抢救性发掘也没有提供有力的证据，发掘简报中提到受盗掘和山体滑坡影响墓室顶部不存且已被严重扰乱，两块铭文墓砖上则刻有梁武帝年号（印象里是“中大通”或是“大同”）。这些证据似乎可以引起人们对于“永宁陵”墓主真实身份的再思考。同样可疑的还有地表遗迹无几的南平元襄王萧伟墓神道。该处墓葬似已发掘，如此则墓主身份当无疑议。萧伟排行第八，为萧秀弟，萧恢兄，为何其神道孤零零地处在墓园最西北角，且方向与诸兄弟不一，反倒与侄子萧暎的神道颇为相近？是与其颇受梁武帝宠爱的六哥临川靖惠王萧宏一样，独享一个墓园，还是另有苦衷？恐怕也只有留待以后研究了。梁吴平忠侯萧景墓32°8’6”N, 118°54’11”E在仙新中路栖霞大道公交站南侧田野里。现存石华表一，石辟邪一。石华表上刻“反左书”，即镜像文字。这种游戏文字在梁代短暂风行过一阵后就淹没在历史中，此处的石华表是为数不多的遗存。左图摄于2018年10月，一个小型的石刻公园已经建立起来。右二图摄于2014年10月，石刻还在田间乱草中。右上图为石华表反左书铭文“梁故侍中//中抚将军//开府仪同//三司吴平//忠侯萧公//之神道”，不法分子盗拓的墨印尚未清除。右下狮子状无角有翼石兽为辟邪。梁始兴忠武王萧憺墓32°8’29”N，118°54’43”E在甘家巷社区公园内。现存辟邪一，辟邪残迹一，碑一，赑屃（碑趺）一。另有两小辟邪，疑似别处随葬墓上物。始兴忠武王碑为南朝书法家贝义渊书，现仍有数百字可辨，为南朝书法为数不多的存世品。论者云唐初书法大家欧阳询有始兴忠武王碑笔意。碑现存于碑亭中，2014年时尚能透过栏杆看见碑文。但随后碑亭就因为严重的盗拓事件换装了防盗门，2017、2018年时再访问就已无法看见石碑。左图为始兴忠武王碑，摄于2014年2月。中上图为网络图像，碑额拓片：“梁故侍中//司徒骠骑//将军始兴//忠武王之//碑”。中下图为西辟邪左后腿残件，大半埋于土中，关节处的纹饰依稀可见，摄于2014年10月。目前此处残件加盖了有机玻璃顶棚，但棚内仿佛温室，植物猖獗，不知对石像来说是否是好事。右上图为凹坑里的西侧碑趺，清理土地时发现，摄于2018年10月。右下图为东侧辟邪，首残，腹部垫有两只小辟邪，做工粗糙，疑为陵园某处较低等级墓葬的神道石像。摄于2014年10月。梁鄱阳忠烈王萧恢墓32°8’31”N，118°54’46”E同在公园内。现存辟邪二，风化开裂严重，右辟邪民国时就已裂为两块（见参考文献中朱偰著作），后用水泥修补。左图为较为完好的西辟邪，摄于2014年2月。右图为东辟邪开裂处，摄于2018年10月。梁安成康王萧秀墓32°8’38”N，118°55’2”E在甘家巷小学教学楼前广场上，以彩钢瓦棚保护。现存辟邪二，碑趺二，华表一，柱础一，碑二（漫漶不可识）。按此墓形制不同于其他墓，两侧华表前后各有两块石碑。萧秀与文人友善，死后陆倕、刘孝绰、裴子野、王僧儒各作碑文一篇，不分伯仲，于是梁武帝特设四块碑。仅存的石华表上原有带盖石兽，民国时存于南京古物保存所，南京沦陷后不知所踪。左上图为东辟邪，体量较前述几只为小，但保存状况较好——从朱偰所拍黑白照片中即可看出，此处石刻民国时即散落在农家院舍之间，后又划入甘家巷小学地界，加盖顶棚保护，故不像前述几只石兽饱受日晒雨淋之苦。左下图为碑趺特写，南朝的赑屃尚且不像后世精雕细琢，有几分写意的风格。中图为仅存一华表。右图为石碑。均摄于2018年10月。梁桂阳简王萧融墓32°9’11”N，118°55’31”E在金陵石化南京炼油厂家属区的小公园里，大致在南炼中学与南炼小学之间。现存辟邪二，发掘发现华表顶端带盖石兽一。西南侧石兽剥蚀严重，表面有大面积修补，北侧较为完好。两辟邪体量巨大，与萧融墓地处东侧尊位相对应。桂阳简王萧融也正是甘家巷地区所有明确身份的墓主中最长者。按桂阳简王在梁朝建立之前被齐东昏侯萧宝卷杀害，此处曾被讹为其嗣子桂阳敦王萧象墓。但通过出土墓志铭确认了墓主身份。左上图为华表顶盖小石兽，首缺。在如此巨大的石辟邪身前倒也显得威风凛凛。左下图为西南侧石兽，上颌、两翼都能看到明显的石料贴补的痕迹。两图摄于2018年10月。右图为东北侧石兽，保存较为完好，带盖小石兽就在其面前地上。摄于2014年2月。陈文帝陈蒨永宁陵32°8’15”N，118°55’35”E不同于王侯墓前的无角狮子状石兽辟邪，永宁陵神道石兽为帝陵级别的独角麒麟与两角天禄，暗示了此处墓主独特的身份（见上文讨论）。在我看来，这里是南朝诸石刻中最华美的一处。有此一处天禄麒麟，足以奠定南朝石刻在中国艺术史上的地位。墓主人扑朔迷离的身份与石刻偏僻难寻的地理位置更增加了它的传奇色彩。石刻在南象山狮子冲，即南象山公墓对面小山的山坳里，下了车仍需要在野草与灌木疯长的荒地里披荆斩棘地走数百米。存麒麟一（西侧），天禄一（东侧）。天禄颈部已断，用水泥修补。这一处很能体现这些年来文物保护水平的进步。下图左上为2014年2月拍摄，石刻没有任何保护措施，垃圾遍地，甚至还有临时搭建的窝棚。左下图是2018年10月拍摄，已经加装了多个监控摄像头（太阳能电池板处），周围也全部清理干净，开出一条小道。左上图为永宁陵石刻全景，左侧为天禄，右侧为麒麟。左下两图为麒麟侧面与背面照。右侧两图为天禄的侧面与背面照。不同于石辟邪采用的线刻技法，麒麟天禄周身刻有浮雕纹饰，且两翼更加窄小，显示出更明显的装饰风格。石兽体量巨大，但从图片中完全没有如萧融墓辟邪一般的笨重、压迫感，反倒显得轻盈灵巧，仿佛随时可以载着墓主腾跃升天。梁南平元襄王萧伟墓32°9’14”N，118°53’30”E在恒谊路东公交站东侧写字楼旁的公园里。存柱础二，石柱残迹数段，倒伏已久，水蚀痕迹明显。传萧伟墓曾出土墓阙残件，可能也是南京南朝石刻中出现的墓阙孤本，但是原址上仅标出而未见到实物。左图为保留了半截石柱的东侧柱础，不难看出萧伟墓石刻体量之卑小，不及甘家巷村一带诸王墓，与此墓偏居陵园西北角对应。摄于2018年10月。右图为西侧倒伏的华表残件，水蚀严重，几乎不辨形状。摄于2017年2月。梁新渝宽侯萧暎墓32°8’58”N，118°54’33”E在炼西路铁路道口西南侧。存华表一。按石仪天下博文以及多年前的互联网图像，该处华表应在农家院子里，只露一个头出来。但我没有赶上。2017年2月走访时四周早已拆迁，石柱保存在临时加盖的水泥棚屋里。地面被加高。屋子已在地平面下，四面渣土，石柱四周积水颇深，情状惨不忍睹。2018年10月再去时棚屋仍在坑里，但四周渣土已被清除，且加装了防护网和监控设备，不能再凑近看屋子里的情况了。现在看2021年的卫星图，似乎石柱已经得到了比较妥善的抬升。只是民国时朱偰先生赖以确认墓主的铭文应该已经被永远地磨灭了。左图及右上图摄于2017年2月，可以看到积水对石柱的侵蚀。右中图摄于2018年10月，此时这一区域已禁止进入。右下图为2021年10月的卫星图，从地面和投影可以看出市政部门应当已对华表进行了发掘和抬升，似乎柱础也已经显露地表。南京栖霞-其它宋武帝刘裕初宁陵32°3’52”N，118°55’20”E刘寄奴出身京口寻常巷陌，与仪征只隔着一条长江，使人倍感亲切。但他细推算来也是汉楚元王刘交的后人。义熙北伐气吞万里如虎，却因为东晋政局不稳而虎头蛇尾，辛苦打下的关中旋即拱手送给了他人。之前看唐人《南北史续世说》说宋武帝写字难看，臣下建议写大字，意思是大字有气势。在西安碑林看《淳化阁帖》刻石（或许是），刘裕的大字尤其显眼。初宁陵石刻在马群麒麟铺街道两侧，存麒麟一，天禄一。2014年去时是一大片城中村，又因靠近麒麟门立交，大车奔流不息，隐隐为石刻的安全感到担忧。看2021年的卫星图，一大片区域都拆迁了，石刻上加盖了保护亭。两件石兽相去甚远，大约应了史料中齐竟陵王萧子良修建西邸时挪动初宁陵石刻的记载。按《资治通鉴》载宋文帝修缮初宁陵事，初宁陵的结构似乎与后代相异，有墓阙和标识（大约是木头做的），不过都已不存。石刻风格本身也与后期迥异，直逼东汉（如雅安高颐墓），仅头部、两翼和四肢有必要纹饰，显示出一种古朴雄浑的气势来。左图为麒麟，首残，右图为天禄，四足残。据民国旧照片，麒麟半埋于土中，因此躯干部份较头部完整。当地村民视石兽为祥瑞，春节会在其颈部绕红绳，胸前贴福字。摄于2014年2月。梁临川靖惠王萧宏墓32°5’17”N，118°54’57”E在南京地铁2号线学则路站附近，已被辟为公园。存辟邪一、华表二、碑一、碑趺一。南朝墓葬选址与后代不同，倾向于山间洼地，地势低湿处，以萧宏墓尤甚。石刻四面被水环绕，九曲桥和保护亭点缀在湖上。风景固然不错，但给拍照带来了极大麻烦。临川靖惠王是颇受梁武帝喜爱的弟弟，得以独享一个墓园，且石刻体量巨大，气势恢弘，若要一窥全貌只有划着船在湖上拍摄。按萧宏墓似乎原有两只辟邪，另一只于近年遗失。但是记不太清，需要查朱偰《建康兰陵六朝陵墓图考》，手头没有资料。左上图为萧宏墓石刻全景，近处为石辟邪。左下为碑，碑文不可辨。但碑侧浮雕保存完好。右图为带盖华表，盖顶石兽遗失。据民国照片，石碑倾覆土中，带盖华表倒塌，但构件完整。另一处无盖华表则一直矗立。摄于2018年2月。笆斗山徐家村失考墓32°8’39”N，118°50’26”E - 未走访，推测方位存华表一。原先在厂区内，遂未探访。但根据2021年卫星图，厂房已经拆迁，附近似乎在兴建轨道交通的车库。如此则此地将来或与地铁、轻轨某线终点站相近，查网络上南京轨道交通规划图，此处疑似1号线北延线终点二桥公园站的附属建筑。徐家村石刻卫星图。箭头所指，黄色地标左侧的黑线即为华表的投影。旁边的建筑工地显示出铁道并轨的特征，而红色矩形处正在兴建围墙，疑似火车车库。考虑到新建铁路的工程量，这里城市轨道交通似乎是更合理的推测。狮子坝村失考墓32°3’47”N，118°54’3”E - 未走访，推测方位存石兽一。按此处与刘裕初宁陵颇为相近，疑为初宁陵的陪葬墓。传闻石兽已失窃。2021年卫星图显示此处已被拆迁和清理，未找到石刻存在痕迹。方位是2018年时根据旧照片的相对位置和历史卫星图层推测出来的。南京江宁江宁一带的石刻遗存级别低于栖霞，石刻多为梁武帝子侄辈所设，保存状况也多不理想。一方面是较低等级贵族石刻本身工艺较为粗糙，只有一星半点留存的缘故，另一方面也可能是江宁一带的工业化、城镇化较栖霞更为剧烈。大多数石刻在2014年走访时就已散落拆迁荒地和工厂用地之间，而此时栖霞一带的石刻不是在田间地头就是在七八十年代兴建的国企职工小区内，遭受的破坏远不及江宁石刻。而近几年随着保护措施的落实，城市延伸造成的破坏已经大大减小，使得栖霞石刻多得以保全。陈武帝陈霸先万安陵31°58’2”N，118°52’51”E在江宁区上坊石马冲一带，存辟邪二。从“石马冲”这一不同于前文所记“麒麟”、“狮子”之类的地名即可想见万安陵石刻所呈现的独特艺术风格。不同于梁代辟邪浑圆硕大的体型，万安陵石刻显得更加修长，且爪上只有四指（梁辟邪五指）。按此处应为疑陵，史料载与陈武帝陈霸先同为平定侯景之乱功臣，后被其杀害的的名将王僧辩，其子在陈朝灭亡后率王氏旧部私发万安陵，墓室破坏殆尽。很难想象陵前石刻能全头全尾地保存至今。此外若此处与前文所述永宁陵皆不虚，两位皇帝陵前石刻的差异也让人感到不可思议。南朝石刻艺术发轫于宋，梁武帝年间登峰造极，迄侯景乱梁，戛然而止。万安陵石刻作风绝不类梁武帝年间，且爪的数量与齐石刻等同，形态上与丹阳水经山失考墓石刻有相似之处，或许是齐代遗存——但如此又将成为类似于永宁陵的一例混入梁代墓园的其他朝墓葬。又或许是梁晚期至陈朝的墓葬，那这一处石刻也多少反映了侯景之乱后江淮一带百业凋敝的事实。左图为体态修长的西辟邪。右图为东辟邪侧面。东辟邪显得壮实一些，但颈部的长度以及弯曲幅度都明显大于梁代辟邪。摄于2014年7月。梁建安敏侯萧正立墓31°55’22”N，118°54’25”E在南京海事职业技术学院东北角的荒地里，存辟邪二，华表二。周围杂草丛生，水系复杂，甚至可以称为沼泽，唯一的好处就是无论是学生还是社会人员都不太方便进出。此处神道几乎是东西走向，南辟邪头部仿佛削去一块，殆不可解。华表或许是受到积水经年累月的侵蚀，下半部分已经变得很细，有倾覆之虞。不同于栖霞石刻群，萧正立墓华表柱础为圆盘形，不知是等级差异还是风格演变。与萧暎墓类似，此处的华表所刻文字是《建康兰陵六朝陵墓图考》中确认墓主身份的重要依据，但2014年走访时文字已经完全不可辨认。左图为华表，石柱偏下部分受到严重的侵蚀，所幸现在几乎见不到水。中图为北辟邪，腿部以下也有明显的侵蚀痕迹。右图为两辟邪全景，可以看到南辟邪头部明显的缺失。摄于2014年7月。侯村失考墓31°56’37”N，118°53’34”E在高铁江宁站东北侧，侯焦路西侧路旁，存辟邪二、华表一。按此处石刻体量卑小，故又称“侯村石马”。与耿岗、后宋墅失考墓颇为相近，或为一处较低级的贵族墓葬。此处石刻的保护亭修建较早，由于临近公路且缺乏清理，保护亭的玻璃积灰严重，使图片的质量非常差。尤其是华表，既高又模糊，很难看清楚保存状况——考虑到它近邻的两处石刻保存状况，这或许也是两害取其轻吧。华表柱础与萧正立墓类似，为圆盘形。左上图为华表及保护亭，右图为西北侧辟邪，表面严重风化。摄于2014年7月。左下图为相机伸进保护亭底部缝隙拍摄的辟邪表面特写，可以看到花纹磨灭殆尽，甚至前肢末端的小翼都很难分辨。摄于2017年2月。后宋墅失考墓31°56’11”N，118°54’15”E在侯焦路、月华路、望溪路和南京高速齿轮厂相交处四边形荒地内的池塘中，存华表一。按本世纪初旧照片，华表本在田间，露出高度与现在差不多，不知为何竟沦落到成为池塘中的一处孤岛，既不方便拍摄，又遭积水侵蚀。根据2021年的卫星地图，情况依然没有改善。此处荒地似乎完全被四周的围栏围死，成为城市的一个被遗忘的角落，2017年寻访时是从高速齿轮厂南侧的员工自行车车棚围栏处找到一个缺口翻了进去。荒地里大约只有几处窝棚，透过草丛能察觉到警惕的眼神，但终究没有人出来喝止我的胡作非为。湖中的华表，摄于2017年2月。耿岗失考墓31°56’45”N，118°54’16”E在高速齿轮厂、长风新能源与望溪路之间的荒地中，存华表半截。耿岗、侯村、后宋墅石刻都得名于曾经的村庄，但随着工业园区的兴建而搬迁拆毁。田间地头、村头巷尾或许不是保存文物的妥善安排，但借助人民群众的伟力，至少能够保证这类微小残迹能够存活下去。此处石刻原存华表残迹两截，耿岗村拆迁后均不知所踪，引起了一些关于石刻是否失窃的讨论。目前看至少一截还留存于世，被用水泥固定在了原址（国家重点文物保护单位，不得不原址保护），并有监控看管，不至遭受与狮子坝失考墓石兽同样的不幸。依稀记得曾见过资料说另一截存于江宁博物馆或六朝博物馆，但找不到来源了。左图为华表残件与文保碑的对比，文物甚至没有文保碑大，依稀可见瓠棱纹和绳纹。右图为正面特写。摄于2017年2月。官塘失考墓31°56’3”N，118°55’10”E - 未走访仅见于朱偰《建康兰陵六朝陵墓图考》。GPS数据是根据所附地图标注的大致位置。按此处石刻原存一华表，是作者与于民国年间（土地革命时期）走访江宁、上元县耆老得知的。采集资料前数年就已折断没入水中，仅剩一石块微露地表。近百年时间过去，应该不剩下什么遗迹了。方旗庙失考墓31°51’00”N，118°35’45”E在江宁区江宁镇石刻湖公园，存石辟邪二。方旗庙失考墓孤悬南京西南角，与南京城区相去甚远，从二号线终点油坊桥站坐车还要近半小时。倒与马鞍山市区颇近。虽然与其它石刻同在江宁，但是之间的距离甚至比江宁石刻群到栖霞石刻群（以及下文的镇江句容石刻）还远，需要单独跑一趟。单从地理上分析，距离最近的南朝墓葬也位于西善桥附近，而且是刘宋墓葬。孤零零的十分显眼。论者云此处或为梁元帝萧绎陵。承圣三年，江陵一炬，中兴之道遂穷。后陈文帝诏令自江陵迁葬梁元帝于“江宁旧茔”，其母阮文宣太后墓侧，丧仪悉从梁制。按江宁区地界是原江宁上元两县合并来，上文的其它江宁石刻都在原上元县地界，此说似乎有理。此处石刻体量中等，与萧正立墓相近，作风也是典型的梁代风格。唯独受水侵蚀，花纹莫辨，且北侧辟邪仅存半只。梁元帝此人实在不讨喜，多少是身体上的缺陷导致了心理上的障碍。“半老徐娘”的绿帽男主即是此君。侯景之乱中自江陵起兵勤王，却一心只想坐收渔利，间接逼死兄弟镇北王萧纶，还冠之以恶谥“携”；攻下建康后放任手下平毁长兄昭明太子墓；改兄弟萧纪一族人以恶姓“饕餮”；又一意孤行迁都江陵，西魏来攻旋即城破，与万卷藏书一同葬身火海。然而却又颇有才名，以《金楼子》传世，为梁代文学代表人物。按《南北史续世说》，元帝因有眼疾，读书不能过久，遂命人日夜持书朗诵。即使睡觉时，侍从所读章句有任何疏漏，也能即刻惊醒责罚。所谓知识既不等于能力，亦不等于人品，由此可见一斑。上图方旗庙失考墓全景。左下图为北侧半只辟邪，旁边还摆放了一些零散的石构件。右下图为南侧完整的辟邪，花纹不存。摄于2017年2月。镇江丹阳-齐陵南朝齐梁两代系出同宗，同为汉丞相萧何的后裔，世居兰陵，遂称兰陵萧氏。永嘉中萧氏迁居武进，晋朝遂于此侨置南兰陵郡（一个对江淮官话区人不太友好的地名）。按兰陵萧氏自秦汉之际一直活跃到安史之乱，为中国历史上最有影响力的家族之一。这种影响力实际建立于几大家族对政治、经济、文化的垄断上。随着藩镇的崛起以及科举制度的发展，中国历史告别了门阀政治而迈入了巩固的中央集权时代，兰陵萧氏的光辉也就随之散去了。齐梁两朝，皇帝作为兰陵萧氏最显赫的成员，自然要归葬于先祖坟茔旁。因此镇江丹阳的南朝石刻，内容或不及南京丰富，但普遍等级高、做工精美，是研究南朝石刻时无法忽略的话题。或许是县城经济不比省城的缘故，丹阳石刻多散落在田间地头，多数甚至离乡间小道都有一定的距离，有幸逃过城市化、工业化的侵扰，从而保留了一种古朴的静谧感。但随之而来的就是缺少必要保护措施——从走访结果来看，石刻附近都安装了摄像头，但除此之外没有任何围栏、遮挡，或保护性开发措施。齐朝帝陵多环绕丹阳水经山修建，分布较为稀疏且交通不便，若无汽车代步则绝不建议只身前往。由于对丹阳不很熟悉，难以用常用地名表述石刻位置，一切以GPS数据为准。南齐享祚二十七年，历七帝，外有追封两帝，现存陵寝数量基本能一一对应。齐宣帝萧承之永安陵32°4’17”N，119°39’38”E在胡桥林场附近，麒麟路东侧田里。存麒麟天禄各一，西侧首缺而东侧角缺，故不能断定种类。观其体态与梁代麒麟天禄殊异，身体扭曲幅度更大，显得更加修长灵动，与南阳东汉宗资墓石兽类似。爪四指，前爪明显抓握了某物体，或为我国传统石狮形象的源流。周身浮雕如胡须、羽翼等已有梁代石刻雏形，但题材不及梁代丰富和立体。上图为永安陵全景，两石刻在田埂上。左下图为完好的东侧石兽，角缺，疑为麒麟；右下图为西侧石兽，注意前爪所持物体。摄于2018年10月。齐高帝萧道成泰安陵32°4’23”N，119°39’25”E - 未走访在永安陵西北，与之隔高速路相望。按此处神道石刻不存。照片仅见于朱偰《建康兰陵六朝陵墓图考》中，民国时尚存麒麟躯干一。有说云石刻在十年动乱时期因占用田地而被“破四旧”，遭炸碎清理。坐标根据图考所附地图标注，记录于此，以示不忘。齐武帝萧赜景安陵32°0’53”N，119°41’14”E不在水经山陵区而孤悬于其东南侧的前艾镇农田中，与常州相去不远，为齐梁诸陵中最偏东者。之所以能确定为齐武帝陵似乎也与《齐书》中记载的武帝诏令有关。存麒麟天禄各一。西侧麒麟据《建康兰陵六朝陵墓图考》记载曾倾覆于水塘中，受流水侵蚀严重，仅能分辨形状而已。东侧天禄保存较好，仅下巴缺失。作风与永安陵石刻相类。高帝萧道成十三岁得长子武帝萧赜，即使在兵荒马乱，门阀糜烂的南朝也属于尤其早的。由于两人年龄相去不远，武帝在高帝开创齐朝的过程中兼有继承人与合伙人的双重性质，深知创业之艰难，继承帝位后也保持了高帝的简朴勤政之风。江南政权在经历了刘宋末年的政变与战乱后获得了十四年宝贵的喘息之机。武帝十八岁得长子萧长懋，居宫中多年协助武帝处理政事，然而却英年早逝，其子鬰林王萧昭业成为幼年储君。武帝于同年宾天。左、中图为东侧保存较完好的天禄，两角已残，仅在头顶存有两个发髻似的残迹。纹饰与永安陵石兽类似，但体态更为拘谨和保守一些。右图为西侧麒麟，曾倾覆池塘中，受水流侵蚀严重，仅留有一形状，以及头部少量花纹可辨。摄于2018年10月。齐景帝萧道生修安陵32°3’43”N，119°40’44”E人云纳于大麓藏之名山，永宁陵与修安陵石刻之谓也。齐景帝修安陵石刻在胡桥林场密林中，深居水经山的山坳里。从单车道的村道上走林间的土路尚要十分钟左右，倘夏天寻访免不了披荆斩棘之苦。但此处石刻保存完好、纹饰精美、体态灵动，为齐代石刻之最佳者，又不可不去。现存麒麟、天禄各一。齐景帝为齐明帝萧鸾父，被其子明帝萧鸾追封为帝。明帝一朝是齐代政局最后的稳定岁月，短短五年光阴留下了一千五百余年不灭的艺术佳作，于时人是民力将尽的悲哀，于后世则是一个遥远年代的珍贵回响。上二图为东侧天禄，两角残。下二图为西侧麒麟。两石兽体态修长，通体遍布纹饰，姿态较武帝陵扭曲更甚，别具灵动之美。此时石兽的两翼仍然是写实为主，与永宁陵石刻相比更强调羽翼的功能性，花纹多用线刻技法，因此显得较为宽大笨重，较多地保存了以南阳宗资墓为典型的东汉石兽的特点。膝部以及后腿的羽毛装饰此时尚未出现，仅腹部饰有已成惯例的浮雕翎羽。摄于2018年10月。水经山失考墓32°5’4”N，119°41’42”E武帝萧赜早逝后，南齐亡国乱君相属，先有鬰林王萧昭业，海陵王萧昭文两代幼年君主，后有旁支萧鸾篡位，将高帝、武帝子嗣屠戮殆尽。明帝享国五年，又有其子东昏侯萧宝卷滥杀朝臣，城破被杀。随后萧宝融被梁武帝萧衍拥立为帝，时萧衍大局已定，和帝傀儡而已。齐朝短短二十七年竟有四位废帝，使得几处失考墓墓主身份的考证困难重重。水经山北，建埤路上，水经山、烂石弄两处失考墓，论者多以为是鬰林王与海陵王墓。两者俱以王侯礼下葬，且两墓葬与高帝陵相去不远。东昏侯与和帝的问题留待金王陈一节讨论。此外，从梁代帝陵与王侯墓分布的经验来看，两处失考墓在帝王陵区内，地理位置和石兽等级的失调多少也暗示了墓主的特殊身份。水经山失考墓石刻在建埤路东侧，在公路路基与水库之间的树林前。存两辟邪，体态卑小，纹饰简单。两翼作风与梁代相似，可见王侯墓石刻所用技术变化不大。体型上相比梁代辟邪明显更修长，且爪四指，从中可以一窥两朝石刻作风的差异。神道不同于帝陵，为东西走向。左图北侧辟邪，右图南侧辟邪。两者甚小且花纹漫漶，仅有两翼可依稀分辨。摄于2018年10月。烂石弄失考墓32°4’41”N，119°41’38”E自水经山失考墓沿建埤路向南七百余米，在路西侧的碎石岔道两侧，神道东西向，存坐狮二，南侧残。若无三城巷失考墓石兽出土，此处的坐狮几乎是南朝孤例，当尤其值得注意。从其两翼可以看出，所谓坐狮，实际上仍是辟邪，与北朝石虎石狮绝不相类。至于端坐的辟邪与行走或站立的辟邪的等级差异，则需留待专家细细讨论了。“烂石弄”这一地名恰如其分地表现了此处石刻的卑小与残破。所谓王侯将相，千载之下，不过几块烂石而已，令人不禁想起老杜“苑边高冢卧麒麟”句。唐人尚有如此感慨，何况今人之视南朝，后人之视今人乎？左、中图为北侧坐狮，从其前臂的小翼可以看出仍是辟邪，尾部也是辟邪式的一根长尾。右图为南侧坐狮残迹，地名烂石，此之谓欤？摄于2018年10月。金王陈失考陵32°3’17”N，119°41’49”E在胡高路南侧往陈家村村道尽头的田间树丛中。此石刻也是极其偏僻难寻的一处，免不了披荆斩棘开辟道路。该失考陵得名于附近的金家、王家、陈家三个村落，其中只有陈家在胡高路南。从其得名之艰难亦可想见石刻的偏僻，以致名无可名，选取了“金王陈”这一不伦不类的名称。然而不同于建埤路上两处墓葬，此处以帝王级别建造，虽石刻体量不及宣帝等陵，于礼却无可指摘。加之与景帝修安陵相去不远，因此疑为和帝萧宝融之陵。至于东昏侯萧宝卷，一来此人死于乱军之中，以侯爵下葬；而来此人杀害了和帝朝掌握实权的梁武帝萧衍长兄萧懿、五弟萧融，于理于情不至得到如此待遇。梁武帝养子萧综被认为是东昏侯遗腹子，曾秘发东昏侯墓取遗骨滴血认亲。可以想见东昏侯墓在梁武帝朝就已残破不堪，否则以皇子身份，发前朝皇帝陵墓取其遗骨，如何不引人注目？上二图为东侧石兽，疑为天禄，角全失，下颚与前臂残，不知未加保护时何以立住。躯干花纹几乎磨灭，仅有腹、股、前胸的几处浮雕尚能分辨。下二图为西侧石兽，角全失，从残迹看疑为麒麟。躯干花纹同样磨灭，头部与两翼保存较好，尚能看见胡须与羽毛。摄于2018年10月。镇江丹阳-梁陵相比于齐陵沿山排布的荒寂，梁陵要显得热闹得多。这不仅体现在其选址地势平坦、交通方便上，也体现在其排布上——三城巷地界，帝陵密密麻麻，热闹非凡，多少也反映了梁武帝亲近以致纵容亲戚的性格特点。梁朝享祚五十五年，仅武帝萧衍便在位四十七年。其间难说政局长久清明，但也算得上南朝少有的太平年月。加以北魏分裂，外患大为减轻，南朝的社会、经济、文化都出现了欣欣向荣的景象，甚至搁置已久的北伐也被重新提起。因此存世南朝石刻，以这一时期为最。如前反复提到的，梁陵石兽以整体气势取胜。论及花纹的繁复，体态的灵动，或许反不如前朝，但整体效果却远胜之。如果说齐代石兽更接近于想象中的“龙”的话，那梁代石兽更类似于狮。这种独特的风格随着南朝的覆灭也消失在了历史长河中，等到宋明两朝再次把麒麟天禄作为神道石兽时，其形象已经演化为龙与鹿的杂交种，温顺有余而气势不足，再无南朝那种灵动的想象力。太清二年，侯景叛乱，武帝困死台城。承圣三年，西魏陷江陵，元帝自焚。随后陈武帝陈霸先于建康拥立敬帝萧方智，西魏吞并四川并于江陵拥立西梁萧詧，梁朝故地遂一分为三。陵口石刻东兽 31°56’49”N，119°39’28”E西兽 31°56’51”N，119°39’23”E在陵口镇萧梁河两侧，存麒麟天禄各一。正如其名所示，此处石刻并非为某一帝王所设，而是整个梁代陵园的大门。两石兽护卫的也并不是某条神道，而是梁代开凿的运河，萧梁河。此河或专为运送修建陵园石材而开，或许梁朝君主谒陵时也是乘船进入陵园——也算是颇具南方特色了。两石兽体量巨大，目测甚至略大于陵园内的石兽。东侧麒麟在工厂围墙外的菜地里，显得有点冷清，靠近围墙一侧花纹清晰，而另一侧漫漶不可辨，疑曾倾覆土中。西侧天禄四肢残，在陵口镇陵口村的村民广场上。小孩子时常攀着天禄的两翼爬上爬下，热闹则热闹，却不免使本不清晰的浮雕更加磨灭了。上二图为萧梁河东侧麒麟，角残，背阴面纹饰清晰可辨，两翼窄小，花纹以浮雕为主，与永宁陵石刻类似。后肢与肘部的羽毛纹饰也已出现。头部与身体的比例相较齐陵石刻更大。下二图为河西侧天禄，双角与四肢残，纹饰与麒麟类似但磨损更为严重。脊背常供孩子攀爬，已经磨得光亮，依稀可见浮雕羽毛。摄于2018年10月。齐明帝萧鸾兴安陵32°0’45”N，119°39’11”E陵口与三城巷陵园虽在南北一条直线上，直线距离仍有七公里有余。自萧梁河北上并不能直接到达，而需在其干流九曲河再换车走三城巷陆路。再走两公里不到则是最南端的兴安陵。三城巷地界，皇帝陵寝的密度全国上下罕有其匹，相去最远的建陵石刻与修陵石刻仅有五百米不到，而修陵与庄陵石刻间更是只有约一百米。所有石刻均在三城巷主路西侧，按辈分从南向北依次排列，神道呈东西走向，自主路向西延伸。兴安陵现存麒麟一，天禄躯干一。按此处陵寝几乎确为梁陵，不知何人据何考证为齐明帝兴安陵。从陵园排布的规律上看，当为武帝萧衍的某位祖辈或者伯父辈。麒麟面部残缺，四肢和尾部为后补。躯干花纹保存完好，观其两翼作风，与陵口石刻类似甚至稍晚，与永宁陵石刻类似。天禄仅存躯干处残石。左、中图为兴安陵麒麟，作风具有明显的梁代特征——大头、小翼、浮雕羽毛，身体粗壮有力，花纹少于齐代但更加立体。右图为天禄残石，仅剩前半个躯干，整体皲裂，仅有两翼花纹依稀可辨。摄于2018年10月。梁太祖萧顺之建陵32°0’49”N，119°39’11”E在疑兴安陵北侧一百二十余米处，伸到与之平行。存麒麟天禄一对，石华表一对，碑趺一对以及墓阙基址残石若干。与本文所述诸陵的残破荒寂相比，建陵之完整，堪称奇迹。此处墓葬也完整反映了梁代神道石刻的一般范式，如本文开头的示意图所标注的。但仍有些许出入——石华表有字一侧并非对神道口，而是两面相对；华表与石兽间尚有墓阙残迹，为其它石刻所未见者。按梁太祖乃武帝之父，登基后追封为帝，旋即着手营造帝陵。就石兽而论，建陵石刻尚未形成南梁独特的艺术风格，仍保有浓重的南齐气息，甚至形象较修安陵石刻来得更加呆板僵硬。或许也可从中一窥齐帝陵所应有的完整格局。按庾子山《哀江南赋》云，“北阙龙吟，东陵麟斗”，即指侯景之乱前夕建陵石兽之异象。本为神道护卫之石兽竟翩翩起舞，神道之中又有两蛇相斗，遂知太清之遽衰。另一说则大约是《建康兰陵六朝陵墓图考》引《南齐书》，讲石兽雕刻好经船运送至码头时，竟自己跳上岸去。两侧石华表上书“太祖//文皇//帝之//神道”，虽略残但仍可分辨。右侧为右行正书，左侧为反左书。按朱偰《建康兰陵六朝陵墓图考》载，此处字迹前清时因地震有所脱落，北洋年间又被凿下“保管”，才得以落得今天的残破境地。如此“保存”行径，殆不可解。上图为建陵神道两侧石刻全景。左中图疑为麒麟，没有角的照片，自己也不太记得清楚。中图为天禄。石兽的体型、花纹全然齐朝作风，只是姿态上失去了曾经大幅度的扭曲和灵动感，反倒显得拘谨。左下图为碑趺，纵观现存碑趺，变化并不如石兽般大。中下图为墓阙残石，不知有何用处。右下图为华表反左书文字特写。右图为华表全貌——较甘家巷与江宁诸王侯墓华表更显粗壮，也更高大。结构大体一致，但纹饰上与后期华表（萧景墓、萧绩墓石刻）相比 更显朴素，铭文石板下侧没有装饰图案作为托举，石柱的绳纹下侧也只是一圈抽象的交龙图案。梁武帝萧衍修陵32°1’3”N，119°39’11”E在建陵石刻北四百余米处，存天禄一。从作风来看已有明显的梁代风格，头部放大，两翼缩小，躯干粗壮。只是两翼尚在写实与写意之间徘徊，虽然宽度已缩小，但仍显得有些粗笨。前肢关节处的小翼已经出现，但后肢不知是花纹磨损还是本意如此，装饰性略逊一筹。相比齐代，天禄头部得到了强调，但似有矫枉过正之嫌，石兽整体显得有些头重脚轻。值得注意的是天禄的两角，作了镂空处理，这大概也能解释其它天禄的角为何全都残缺。修陵天禄的镂空双角是整个南朝石刻中的孤品，历经一千五百年风雨得以幸存，实属不易。相比之下，齐梁两代麒麟的独角多不镂空，且更加粗壮，故在永宁陵、修安陵等石刻上得以保全。梁武帝其人实在太过复杂，不知从何谈起。早年身居“竟陵八友”，以文才行事；中年开辟基业，与民休息，读任彦升《天监三年策秀才文》，精诚求治之情溢于辞章；晚年佞佛舍身同泰寺却又冷遇达摩祖师，使其一苇渡江；宠幸亲戚以致纵容，家中涌现了昭明太子、简文帝、元帝等一批英才；被困台城时前来勤王的诸皇子却勾心斗角，梭巡不前，落得饥渴而死的下场。身后千载，只有一匹天禄不离不弃。左、中图为天禄全身，已有明显的梁朝风格，只是比例上还欠协调，纹饰上还略保守。右图为天禄双角特写，可见镂空部分石料之脆弱，保存之不易。天禄头颈的数条裂缝，使人触目惊心。摄于2018年10月。梁简文帝萧纲庄陵32°1’5”N，119°39’10”E在修陵石刻北约一百米处，存麒麟半只。按《建康兰陵六朝陵墓图考》，此麒麟曾倾覆土中，故而一侧花纹漫漶一侧花纹清晰。麒麟仅存前半身，比例协调，姿态雄伟，气势逼人，全然梁朝作风。虽然残剩半只，却有维纳斯断臂之美。尤爱肩部两翼造型，既有气势又不乏灵动。然而保存状况堪忧，地上散乱着不知何时崩落的碎石，甚至有似乎是新近脱落的带花纹石块，疑心是羽翼或胡须的残件。石刻长期暴露的一侧遍布裂纹，整体似有解体之虞。庄陵的萧瑟一如简文帝的命运。简文帝年轻时文学成就颇高，与侍臣庾肩吾等开梁代宫体诗之先河。台城破后被侯景扶持为帝，谋划政变时优柔寡断以致事泄，长子萧大器与诸皇子被害，自身旋即被废，囚于永福省，随后遇害。有《简文帝幽絷题壁自序》传世，字字泣血。初读成诵，咏叹良久，至今不忘，于此录之： 有梁正士，兰陵萧世缵，立身行道，始终如一。风雨如晦，鸡鸣不已，弗欺暗室，岂况三光。数至于此，命也如何？左图为麒麟面向道路的一侧，常年暴露在外，侵蚀严重。右图为保存较为完好的另一侧。头部亦遭风化，角不存，仅有头顶一鼓包。摄于2018年10月。三城巷失考墓石兽坐标： 32° 3’35”N，119°39’10”E按此处石刻似乎不在国家重点文物保护单位名单上，因而可以迁移。根据我能找到的资料显示，原址应留存有两细小石柱，后经发掘发现一坐狮，先保存于丹阳天地石刻园内，即坐标标示位置。原址应在建陵与修陵之间的小路上，但是遍访而不得，网络资料也语焉不详，且多为2013-214年间的记录，如今看来将近十年过去，距离寻访也有五年，不知是否被搬动过了，遂留一遗憾。保存在石刻园的坐狮体型甚小，倾覆前疑遭多年风化，加之后续的土蚀，已经看不出什么花纹。姿态与烂石弄失考墓石刻倒也不相像，前肢并非并排摆放。尾巴也呈上竖状，除了头部全然没有辟邪的影子了。此处失考墓规格甚低，疑心是帝王陵旁的陪葬墓。石兽应摆放在神道右侧，面朝神道口。左图为自神道口向内看视角，右图为另一侧。石兽风化严重且有残损。前肢下半部分为出土后用另一颜色石块修补，不足为凭。但从残存部分也可看出前肢并非并排，而是呈行走状。尾部则形似覆斗。摄于2018年10月。镇江句容南康简王萧绩墓31°58’9”N，119° 5’7”E在镇江句容石狮村。句容去南京不远，而石狮村有格外与南京江宁相近，因此这里当为另一处南朝梁王侯墓园。只是时过境迁，只留下南康简王墓石刻孑然屹立。存石辟邪二，石华表二。两辟邪技法上似不如甘家巷诸王墓生动圆熟，花纹也更简单，但体量当为梁王侯墓石刻之冠——体态丰腴以致失之笨重。走近视之，压迫感迎面而来。不过经过上文漫长的帝王陵石刻洗礼，再来看石辟邪，顿时有种古朴雄浑的美感。东侧石华表保存状况堪称奇迹，仿佛新刻出来一样，右行正书“梁故侍中中军将//军开府仪同三司//南康简王之神道”。西侧华表保存状态也属难得，只是顶盖被整齐地削掉一块，疑心是被雷劈过，铭文为左行正书，相同内容。华表粗壮，与建陵石刻华表类似，而不像南京诸王侯墓，或许与营造年代有关。与保存完好的辟邪、华表形成对照的是全无踪迹的石碑。华表后是一片水塘，只怕即使有残迹，也早已沉入水底了。句容境内只此一处南朝石刻，显然当地政府更上心一些，早早将石兽加上围栏，辟作公园，公园旁甚至有环卫工人小屋，兼具存放工具和监管文物之用。左上图为西侧辟邪，体型之庞大可见一斑，受制于如此庞大的体量，石兽的姿态就显得有些僵硬。右上图为西侧辟邪，侧面花纹已风化不见。左下图为东侧华表铭文特写，字比萧景墓、建陵华表更细小，保存至今实为不易。下中图为东侧华表花纹特写，与萧景墓华表类似，仅铭文石板下侧的图案不同。右下两图分别为东侧与西侧华表。左上、左下、右下图摄于2014年7月；其余摄于2018年10月。写到这里，也应当告一段落了。本文从2022年2月初一直断断续续写道4月初，中间经历了许多事，但又仿佛一眨眼就过去了，正如我回顾文中这些照片时的感受——不知不觉，快十年过去了。而对于那些石刻，在我未生时，它们就已经在那里；当我离去时，它们还将在那里，所以人与物的感情不能相通。人能移情于物，而物却不会因此而改变什么。有的人，籍物以托永恒，急切地想向这个世界证明他曾经来过。然而物虽无生命，却也不得不遵从自然世界此消彼长的规律。这些规律永恒地作用于一切有生命的、没有生命的，它们不依托于任何实体，所以能够遍布于时间和空间。相比于无生命的物，人唯一的幸运之处就在于能够在短暂的一生内认识这些规律——我们不寄希望于以任何形式达成永恒，但求能够睁开眼，看一看这个世界的法则。那些超脱形体的存在，蕴含着我们一代代人追求的永恒与自由。" }, { "title": "Obtain parameter lists for Grimme&#39;s DFT-D3 and gCP methods", "url": "/posts/Parameter-list-for-Grimme's-DFT-D3-and-gCP-method/", "categories": "Research, DFT", "tags": "Empirical correction, molecular crystals, CRYSTAL, regular inspection", "date": "2022-02-07 15:14:57 +0000", "snippet": "This is a short note discussing how to obtain the critical parameters for empirical DFT-D3 and geometric counterpoise (gCP) corrections developed in S. Grimme’s group. For DFT-D3, part of the parameters are available from its original publication, yet not complete. For gCP, no data is given in published papers. However, they can be easily obtained from the source code of the software posted in group webpage - DFT-D3 and gCP. They are actually toolkit written in Fortran90 to calculate dispersion energy and gCP energy correction terms of a given geometry and based on a given level of accuracy.The latest releases available on Feb. 07-22 are adopted: DFT-D3 v3.2 Rev0 and gCP v2.02.DFT-D3Relatively up-to-date coefficient files for BJ damping and zero damping are available. Specifying functional names by FUNC of DFTD3 sub-block is supported, yet there is a related issue.gCPParameters of gCP mainly depend on basis sets. Open the script ‘gcp.f90’. The following table lists the name of critical parameters and their corresponding variables in the script (line 459~462): CRYSTAL variables SIGMA ALPHA BETA ETA gCP variables P(1) P(3) P(4) P(2) Note that there are 2 other variables in the script, emiss and nbas, which are basis set and element specific. They are defined by the keyword METHOD and the geometry file in CRYSTAL, and therefore cannot be modified. Their values are stored respectively in HFbsname and BASbsname variables in the same script (line 1055~1302), e.g., HFsv and BASsv.The variable RADIUS in CRYSTAL GCP subblock is doubtful here and modification is not recommended. According to the definition in the manual (p.p. 139), it should correspond to the variable thrR, in the script it equals 60 Bohr and offers no help, because it is not a fitted parameter but a cutoff radius for summation.If it means the radius of atom pairs used for gCP calculation, it should be element specific. In line 582~593, cutoff radius from H to Pu are defined in variable rad but not used. r0ab defines the cut-off radii for all element pairs. Values (in Bohr) can be found in line 4017~4800, defined in a pairwise fashion - in total 4465 combinations, almost unreadable.The supported methods and basis sets are listed in the manual. According to my rough comparison, the list seems to be incomplete. Their corresponding variable names are listed in: line 1311~1433 - HF line 1435~1574 - KS-DFT &amp;amp; B3LYP line 1578~1661 - 3c &amp;amp; double-hybrid XC functionalFor CRYSTAL, the supported methods are consistent with those listed in the script ‘gCP.f90’. Even though the supported methods are not listed in the manual, they can be viewed by a test run. Supported values are printed out if the value of method in GCP sub-block is not recognized, which are listed below:CRYSTAL17 available options &amp;amp; default parameters - gCP v2.02 KEYWORD SIGMA ALPHA BETA ETA Hartree-Fock         HF/SV 0.1724 0.8568 1.2342 1.2804 HF/SVP, HF/DEF2SVP 0.2054 0.8136 1.2572 1.3157 HF/SV(P), HF/DEF2SV(P), HF/SV_P (*) 0.1373 0.8141 1.2760 1.4271 HF/DZP 0.1443 0.3711 1.6300 1.4547 HF/631GD 0.2048 0.9447 1.2100 1.5652 HF/MINIS, HF/MINIX 0.1290 1.1549 1.1763 1.1526 HF/DEF2TZVP 0.3127 1.0216 1.2833 1.9914 HF/DEFTZVP, HF/TZVP 0.2600 0.7998 1.4381 2.2448 HF/CCDZ, HF/CCPVDZ 0.4416 0.6902 1.3713 1.5185 HF/ACCDZ, HF/AUGCCDZ 0.0748 0.3811 1.0155 0.0663 HF/2G 0.2461 0.7335 1.4709 1.1616 KS-DFT         DFT/LANL, B3LYP/LANL 0.3405 0.8589 1.2830 1.6127 DFT/SV, B3LYP/SV 0.4048 0.8652 1.2375 1.1626 DFT/SV(P), B3LYP/SV(P), DFT/DEF2SV(P), B3LYP/DEF2SV(P) (*), DFT/SV_P 0.2424 0.6076 1.4078 1.2371 DFT/SVX, B3LYP/SVX 0.1861 0.6171 1.4019 1.3200 DFT/SVP, B3LYP/SVP, DFT/DEF2SVP, B3LYP/DEF2SVP 0.2990 0.6438 1.3694 1.2605 DFT/DZP 0.2687 0.3513 1.6880 1.4634 DFT/631GD, B3LYP/631GD 0.3405 0.8589 1.2830 1.6127 DFT/MINIS, B3LYP/MINIS 0.2059 1.1961 1.1456 0.9722 DFT/TZ, B3LYP/TZ, DFT/DEF2TZVP, B3LYP/DEF2TZVP 0.2905 0.8120 1.4412 2.2495 DFT/DEFTZVP, B3LYP/DEFTZVP, DFT/TZVP, B3LYP/TZVP 0.2393 0.8185 1.4298 2.2247 DFT/CCDZ, B3LYP/CCDZ, DFT/CCPVDZ, B3LYP/CCPVDZ 0.5383 0.6230 1.4523 1.6482 DFT/ACCDZ, B3LYP/ACCDZ, DFT/AUGCCPVDZ, B3LYP/AUGCCPVDZ 0.1465 0.6003 0.8761 0.0500 DFT/POBTZ, B3LYP/POBTZ 0.1300 0.4792 1.3962 1.3743 Special Cases         GGA/MINIS, BLYP/MINIS, 0.1566 1.0732 1.1968 1.0271 GGA/SVP, BLYP/SVP 0.6823 0.8225 1.2811 1.2491 GGA/SV, BLYP/SV 0.2727 0.8055 1.3000 1.4022 GGA/TZ, BLYP/TZ 0.1182 1.0510 1.1287 1.0631 TPSS/MINIS 0.22982 1.47633 1.11300 1.35401 TPSS/SVP 0.6647 1.0792 1.1651 1.3306 PW6B95/MINIS 0.21054 1.35003 1.14061 1.25458 PW6B95/SVP 0.3098 0.6896 1.3347 1.2373 PBE/DEF2SV(P) 0.2424 0.6076 1.4078 1.2371 PBEH3C 1.00000 0.27649 1.95600 1.32492 HSE3C 1.00000 0.28314 1.94527 1.32378 B3PBE3C 1.00000 0.3011 2.4405 2.98561 No Data         RSH2C/MODDZ, B973C - - - - (*): Available in CRYSTAL17 but not included in the script ‘gCP.f90’. Their parameters are guessed from similar cases.B97-3c method doesn’t adopt a standard gCP correction because of the relatively complete basis set. See the B973C keyword in the manual.Note that there are some options included in ‘gCP.f90’ but not in CRYSTAL17, which are not listed here." }, { "title": "Install the LaTeX compiling environment for Sublime Text 4", "url": "/posts/Install-the-LaTeX-compiling-environment-for-Sublime-Text-4/", "categories": "Technique, LaTeX", "tags": "Sublime Text 4, LaTeX, windows", "date": "2022-02-04 23:46:36 +0000", "snippet": "This post is to summarize the necessary settings to establish the Sublime Text 4 as the LaTeX editor. The following features are materialized: Auto completion of LaTeX keywords; Equation, figure &amp;amp; citation preview; Inverse search from the compiled PDF file; BibLaTeX integrated in a single compile command.Setup on Jan. 10, 2022, with Windows 10 21H2. LaTeX compiler: MikTex 21.12P.S. I still recommend Overleaf as a more compatible choice, as long as the template is supported.List of required packages/software MikTeX - LaTeX compiler (TeXStudio is compatible as well, modify the settings according to the documentation); LaTeXTools - LaTeX editor plugin for sublime text; LaTeX Word count - Explicite word counter for LaTeX documents; SumatraPDF - A free and light weight PDF reader. The only PDF reader supporting reverse lookup on Windows platform; Ghostscript - Equation preview and image preview for common formats (PNG, JPEG, GIF, PDF, EPS, PS); ImageMagick - Image preview for other formats.Sublime Text 4 packages are installed via Package Control.Setup LaTeXToolsLink the compilerPreliminary step, not required. The directory of MikTeX executable file should be added to the global environment variable $Path. Search ‘environmental variable’ to modify the value of $Path.Open ‘Preferences/Package Settings/LaTeXTools/Settings - User’, Search texpath and edit the path according to OSs. For Windows users, if the prerequisite is not satisfied, variables texpath and sumatra should be specified as the directory of MiKTeX and the executable file of SumatraPDF. Otherwise the variable texpath can be left blank. The format of texpath should follow the commented line.&quot;windows&quot;: { &quot;texpath&quot; : &quot;disc:\\\\miktex\\\\executable\\\\folder;$PATH&quot;, &quot;sumatra&quot;: &quot;disc:\\\\SubatraPDF\\\\executable\\\\file\\\\SumatraPDF.exe&quot;}Set auto generation for bibliographySearch the same file for builder, modify its value to “script”. Then go a little down to find the variable builder_settings, set the OS-specific commands. In Windows system, the iterative scheme of ‘pdfLaTeX - BibTeX’ is adopted:&quot;windows&quot; : { &quot;script_commands&quot;:[ &quot;pdflatex -synctex=1 -interaction=nonstopmode&quot;, &quot;bibtex&quot;, &quot;pdflatex -synctex=1 -interaction=nonstopmode&quot;, &quot;pdflatex -synctex=1 -interaction=nonstopmode&quot; ]}Figure &amp;amp; equation previewsGhostscriptLaTeXTools can automatically install the Ghostscript for MikTeX, as long as the directory of its executable file is added as the value of either texpath or environmental variable $Path. To manually install and specify Ghostscript, add the folder of executable to $Path or texpath:&quot;texpath&quot; : &quot;disc:\\\\miktex\\\\executable\\\\folder;disc:\\\\ghostscrip\\\\executable\\\\folder;$PATH&quot;For TeXLive users, refer to the documentation, and modify environmental variables similarly.For ImageMagick, manual installation is required. Then set environmental variables similarly.Check the environmentAfter finishing all necessary settings, an automatic system check might be helpful to ensure the settings above function correctly. Click on ‘Preferences/Package Settings/LaTeXTools/Check System’ to run automatic check. Information of installed distributions is also available in the output.Overcome the incompatibility with Sublime Text 4An issue is identified with LaTeXTools on Sublime Text 4 which is probably due to incompatibility: the backslash ‘\\’ goes missing when using auto completion. The solution is from the same page, WeixuanZ’s comment.Click ‘Preferences/Browse Packages…’ to open the folder ‘LaTeXTools/’. Find the script ‘latex_cwl_completions.py’. Comment line 308 ~ 312. In previously commented lines the flaw of ST3 in recognizing backslash is explained, which might be fixed in ST4. # autocompleting with slash already on line # this is necessary to work around a short-coming in ST where having a # keyed entry appears to interfere with it recognising that there is a # \\ already on the line # # NB this may not work if there are other punctuation marks in the # completion if is_prefixed: completions = [ (c[0], c[1][1:]) if c[1].startswith(&quot;\\\\&quot;) else c for c in completions ]Set SumatraPDF for reverse lookupIn the previous section, SumatraPDF has been set as the default PDF viewer for the output of LaTeX. Generating test file is recommended before taking the following steps.After finishing compilation, SumatraPDF should be automatically launched to display the generated file. Meanwhile, in the same directory, there is a ‘.synctex.gz’ file storing the synchronization information. SumatraPDF will show the panel for setting up reverse search only if a document with synchronization data is opened - use an old document also works.Open the menu on the top left and click on ‘Settings/Options’. In the ‘Set inverse search command-line’ panel, enter the command below:&quot;disc:\\\\sublime\\\\text\\\\executable\\\\sublime_text.exe&quot; &quot;%f:%l&quot;Then inverse search is enabled when user double clicks somewhere in the generated PDF file." }, { "title": "Names and Definitions of Popular Basis Sets", "url": "/posts/Names-and-Definitions-of-Popular-Basis-Sets/", "categories": "Research, DFT", "tags": "Atomic Basis Set, regular inspection", "date": "2022-01-29 12:05:52 +0000", "snippet": "In this post are listed the naming schemes of popular basis sets (BSs) that can be found in Basis Set Exchange program and CRYSTAL basis set webpage. Basis sets developed for pseudopotentials are not included in this post, since CRYSTAL code is more commonly used for more accurate all-electron calculations. The correctness of this page are regularly inspected.References: D. C. Young, in Computational Chemistry: A Practical Guide for Applying Techniques to Real-World Problems, Wiley, 2001, pp. 78–91. B. Nagy and F. Jensen, in Reviews in Computational Chemistry, John Wiley &amp;amp; Sons, Inc., Hoboken, NJ, USA, 2017, vol. 3, pp. 93–149. Sobereva, 谈谈弥散函数和“月份”基组, http://sobereva.com/119. D. Vilela Oliveira, J. Laun, M. F. Peintinger and T. Bredow, J Comput Chem, 2019, 40, 2364–2376. L. E. Daga, B. Civalleri and L. Maschio, J. Chem. Theory Comput., 2020, 16, 2192–2201. Wikipedia, Basis set(chemistry), https://en.wikipedia.org/wiki/Basis_set_%28chemistry%29Background knowledgeThe developing proposes of basis setBasis sets in quantum chemistry are developed for different proposes, and therefore different optimization targets are adopted.For BSs developed for the exact electron correlation energy of wave function methods, such as the coupled cluster method (CCSD, CCSD(T)), the target system is typically isolated atoms.For BSs developed for HF / DFT, the target system for the occupied orbitals is isolated atoms. The target system for the polarization orbitals is usually molecules.ContractionThe Gaussian functions used for constructing basis sets are called primitive functions (PGTO), which usually contains more functions than practically needed (contracted Gaussian type orbitals, CGTO). Since the core orbitals are insensitive to different chemical environments, it will be computationally efficient to represent the core with a fixed linear combination of Gaussian orbitals, which is known as contraction.Segmented contractionIn segmented contraction, every primitive function contributes to only a specific contracted function. Suppose 10 PGTOs are contracted to obtain 3 CGTOs:\\[\\kappa_{1}=\\sum^{6}_{\\alpha=1}d_{\\alpha}\\chi_{\\alpha}\\]\\[\\kappa_{2}=\\sum^{9}_{\\alpha=7}d_{\\alpha}\\chi_{\\alpha}\\]\\[\\kappa_{3}=d_{10}\\chi_{10}\\]General contractionIn general contraction, every CGTO is the linear combination of all PGTOs.\\[\\kappa_{n}=\\sum^{10}_{\\alpha=1}d_{n,\\alpha}\\chi_{\\alpha}, n=1,2,3\\]In practice, the situation is usually in the middle. For example, several PGTOs with significant influence might repeat in segmented contraction basis sets, or PGTOs with negligible influences on a certain CGTO might be truncated in general contraction basis sets. The contraction method of the majority determines the contraction type.It is intuitively correct that segmented contraction basis set is computationally more efficient. However, it also requires the simultaneous optimization of the exponents and contraction coefficients, making basis set construction more difficult.Split-valance: n-\\(\\zeta\\) BSsThe distribution of valance electrons is susceptible to chemical environment. To add some flexibility, the valance shell can be expressed as the linear combination of multiple shells (a shell here means GTOs with the same angular momentum) composed of GTOs with different parameters. n-\\(\\zeta\\) indicates the valance shell is split into n shells.For HF/DFT calculations BSs with n beyond 4 or 5 can be regarded as close to the complete basis set (CBS) limit, which means problems related to basis set incompleteness are eliminated.Augmentation: Polarization, diffuse, and tightPolarization functionsTo improve the flexibility of orbitals, another option is to add orbitals with higher angular momentum (in a new shell), and thus the orbitals allows angular distortions.Diffuse functionsThe extended tail of Slater type orbitals (STOs) are poorly represented by GTOs. Therefore to improve the radical flexibility, diffuse functions with small exponential terms are inserted to the valance shells and sometimes also the polarization shells.Tight functionsVery accurate electron correlation calculations also require the angular flexibility for the contracted core orbitals, otherwise the their contributions are cancelled. Tight functions with large exponential terms are defined to fill the gap between the contracted core and the flexible valance orbitals.Pople’s basis setsSTO-nG - The minimal basis set. n GTOs are used to fit an STO.For other Pople BSs, they are segmented contracted, and HF (2-\\(\\zeta\\)) or MP2 (3-\\(\\zeta\\)) optimized. Only the valance shell can be augmented with diffuse functions. In Pople’s BSs, except 1s, s and p orbitals are defined as sp orbitals to improve the efficiency. The naming scheme below is followed:3-21G - The double \\(\\zeta\\) BS with segmented contraction, which consists of: 3 GTOs for cores, 2 GTOs and 1 GTO respectively for split valance shells.6-21G* - The double \\(\\zeta\\) BS consists of 6 core GTOs, 2 + 1 valance GTOs, and 1 d polarization orbital (except H).6-311G** - The triple \\(\\zeta\\) BS with 6 core GTOs, 3 + 1 + 1 valance GTOs and 1 d (or p for H) polarization orbital.6-31+G - The 6-31G BS with diffuse functions for non-hydrogen elements.6-31++G - The 6-31G BS with diffuse functions for all elements.6-311G(2df) - The 6-311G BS with 2 extra sets of d and an extra set of f polarization orbitals. No polarization for H.6-311++G(3df,3pd) - The 6-311G BS with diffuse functions at valance shell for all elements and 3 d + 1 f polarization orbitals for heavy atoms, 3 p + 1 d polarization orbitals for H.Karlsruhe basis setsSegmented contraction BS optimized by HF energy (occupied orbitals) or from cc-PVXZ (polarization orbitals). Parameters for electron correlation calculations are also available. Only the BSs for HF/DFT are discussed.def2 versiondef2-SV(P) - Karlsruhe def2-double \\(\\zeta\\) split-valance-shell BS, with polarization on heavy atoms.def2-SVP - Karlsruhe def2-double \\(\\zeta\\) split-valance-shell BS, with polarization on all atoms.def2-TZVPD - Karlsruhe def2-triple $$ \\zeta BS with diffuse functions on valance and polarization shells.def2-TZVPP - Karlsruhe def2-TZVP BS with an extra set of polarization orbitals for all atoms.def2-QZVPPD - Karlsruhe def2-quadruple \\(\\zeta\\) split-valance-shell BSs, with 2 sets of polarization orbitals and diffuse orbitals.Polarization schemepob versionThe pob-XZVP basis sets are developed by T. Bredow’s group (University of Bonn) especially for solid-state calculations. Its recent update (rev2, 2019) improves the SCF stability.pob-XZVP BSs are based on the def2- series. They are constructed by firstly removing very diffuse PGTOs (exponent &amp;lt; 0.1) and then augmenting the truncated BS with the lowest exponent \\(\\geq\\) 0.1 till the desired accuracy is reached. Meanwhile, high angular momentum polarization orbitals are truncated.pob-TZVP - The triple-\\(\\zeta\\) split-valance-shell BS with polarization on all atoms.pob-[DZ/TZ]VP-rev2 - Revised double/triple-\\(\\zeta\\) pob- series BSs, including the revised version of the unpublished pob-DZVP.dcm versionSystem-specific BSs optimized by basis set direct inversion of iterative subspace (BDIIS) algorithm by L. Maschio’s group (University of Turin). Optimizations are performed by iterating the exponents of def2-TZVP orbitals, high angular momentum polarization orbitals are kept.dcm[Cdiam]-TZVP - Carbon def2-TZVP BS reparameterized for diamond.Empirical extrapolation towards CBS limitIn this section BSs constructed to systematically approach the CBS limit using empirical extrapolation are covered. All of them are general contracted BSs.Correlation consistent BSsDunning’s cc-pVnZ BSs are developed for post HF methods to deal with electron correlation.cc-pVnZ - n = D, T, Q, 5, 6, correlation consistent 2~6-\\(\\zeta\\) split-valance BSs with polarization.cc-pV(n + d)Z - cc-pVnZ BSs with an extra d orbital, to improve the extrapolation to the CBS limit.cc-pwCVnZ, cc-pCVnZ - cc-pVnZ BSs with tight core augmentation.cc-pVnZ-F12 - cc-pVnZ BSs optimized for explicitly correlated F12 methods.Augmentation and “Month” BSsIt is possible to insert diffuse functions to Dunning cc- BSs to reach CBS limit.aug-cc-pVnZ - The cc-pVnZ BSs with diffuse functions for all shells, all elements.However, the diffuse functions for H, and high angular momentum diffuse functions, usually play a minor role. “Month” BSs removes the diffuse functions of H, while for heavy atoms, the diffuse functions are removed in the decreasing sequence of angular momentum, and they are named in the inverse month sequence from August (aug, chemists’ strange sense of humor). However, diffuse functions for s and p shells are kept, and the end point is equivalent to ‘maug-cc-pVnZ’ BSs.jul-cc-pVnZ - aug-cc-pVnZ without diffuse functions for H.jun-cc-pVnZ - jul-cc-pVnZ without the highest angular momentum diffuse functions for heavy atoms.…maug-cc-pVnZ - cc-pVnZ BSs with diffuse functions for s,p shells of heavy atoms.Polarization consistent BSsAdopting the similar methods, Jensen’s group developed the pc-n polarization consistent BSs for HF/DFT calculations.pc-n - n = 0, 1, 2, 3, 4, Jensen’s polarization consistent BSs. The meaning of n is given below. n 0 1 2 3 4 Quality unpolarized DZ DZP TZP QZP 5ZP pcseg-n - The segmented contraction version of ‘pc-n’ BSs, generated by orthogonalization transformation.Other BSs" }, { "title": "Install Anaconda3 and create a new environment", "url": "/posts/Create-a-new-environment-in-Anaconda3/", "categories": "Technique, programming", "tags": "python, Anaconda3, windows, linux, Imperial RCS", "date": "2022-01-26 19:52:11 +0000", "snippet": "This post is to summarize the procedures to create an Anaconda python environment in Windows and Linux systems. Tested on Jan. 08, 2022 with Windows 10 21H2, and on Jan. 29, 2022 with Imperial cluster cx3. Imperial cluster instructions updated Jun. 20, 2022.Windows systemAnaconda 3has been integrated into a application with GUI. After installing Anaconda 3, launch the ‘Anaconda Prompt(Anaconda3)’ application, which is the command line of the software, and setup everything (see below). It is also accessible to available environments / packages through Anaconda Navigator(Anaconda3) with a GUI.Load and Install Anaconda3 on Imperial clusterThe python environment loaded on the cluster is only used for testing proposes. Any demanding jobs are required to run on Anaconda environments. To load Anaconda3, use the command below:~$ module load anaconda3/personalNote: The access to the module ‘anaconda3’ is restricted. The personal edition is recommended.After the module is correctly loaded, using the command below will automatically install anaconda3 to your home directory: ${HOME}/anaconda3/~$ anaconda-setupAlternatively, copying the corresponding shell script into your work directory enables you to make modifications. Then execute the script in your work directory:~$ which anaconda-setup/apps/anaconda3/2019.10/anaconda-setup~$ cp /apps/anaconda3/2019.10/anaconda-setup ./~$ ./anaconda-setupIt takes roughly 1 hr to setup everything. Have a cup of tea.Afterwards, anaconda needs to be initialized. Use the command below to initialize and activate conda commands. The source command should be executed every time the user logs in.~$ ./anaconda3/bin/conda init~$ source ~/.bashrcCreate &amp;amp; setup a python environmentCommand list Create a new environment The ‘base’ environment is the default environment of Anaconda python, corresponding to the interpreter in the install root. The following command is used to create a python 3.6 environment named as ‘py36ase’. The interpreter of the created environment is saved in the subfolder of install root: ‘env/py36ase’ ~$ conda create -n py36ase python=3.6List installed packages/environments~$ conda list~$ conda env list~$ conda info -eCheck available updatesTo update anaconda, do it in the base environment.~$ conda update condaSubstituting conda with the specific package name can update the package in a specific environment.Enter/exist a specific environment~$ conda activate env_name~$ conda deactivateInstall/uninstall packages for a specific environment~$ conda install -n env_name package_name~$ conda remove -n env_name package_nameCompletely remove an environment~$ conda remove -n env_name --allPackage specific issues Atomic simulation environment (ASE) not available ASE cannot be automatically located with the conda install command, though it is listed in Anaconda3 packages repository. Use the command (provided in the link) to install it:~$ conda install -c rmg ase" }, { "title": "Setup the python developing environment for Sublime Text 4", "url": "/posts/Setup-the-python-developing-environment-for-Sublime-Text-4/", "categories": "Technique, programming", "tags": "Sublime Text 4, python, Anaconda3, windows", "date": "2022-01-23 21:31:10 +0000", "snippet": "In this page my setups of python3 developing environment with Sublime Text 4 text editor are briefly introduced. The following functions are achieved. Setup with Windows 10 21H2, Jan. 9-2022. Python interpreters managed by Anaconda 3; Interactive PDB debugger; Command line; Automatically modify the script to fit the Pep8 style; Syntax check and code completion.Create a new REPL environment Step 1: Install package control Press Ctrl + Shift + P. Type ‘install package control’ and enter. Notification will pop out after the installation is successful. Step 2: Install SublimeREPL Press Ctrl + Shift + P. Type ‘Package control: Install packages’ and enter. Type ‘SublimeREPL’ to install this package. Step 3: Create a new environment On the top banner, click ‘Preferences/Browse Packages’, open the folder ‘SublimeREPL/config’. Copy the subfolder ‘Python’ and rename it as any name, say, ‘py36ase’. Restart the software, from the top banner click ‘Tools/SublimeREPL/’. Find the environment with the newly defined name to confirm it has been installed correctly.Link Anaconda 3 to the new environment Step 1： Create the REPL commands In the folder ‘SublimeREPL/config/py36ase’, open the file ‘Main.sublime-menu’ and substitute the word ‘Python’ with the word ‘py36ase’, except the following lines:&quot;syntax&quot;: &quot;Packages/Python/Python.tmLanguage&quot;&quot;extend_env&quot;: {&quot;PYTHONIOENCODING&quot;: &quot;utf-8&quot;}: In lines with &quot;cmd&quot;, substitute the environmental variable &quot;python&quot; with the path of python executable file. Here the ‘py36ase’ environment is used:&quot;cmd&quot;: [&quot;D:/Anaconda3/envs/py3.6ase/python.exe&quot;, &quot;-i&quot;, &quot;-u&quot;],Then the available REPL commands for the ‘py36ase’ environment are defined, which are visible and executable by clicking ‘Tools/SublimeREPL/py36ase/’. Step 2: Edit the captions of commands There is no known issues with an unmodified or even removed ‘Default.sublime-commands’ file. However, just in case, captions and arguments of commands can be defined there. Change the path in &quot;file&quot; lines to the same folder: &quot;file&quot;: &quot;config/py3.6ase/Main.sublime-menu&quot;: Change the &quot;caption&quot; line into any name, and choose the corresponding &quot;id&quot; line in the ‘Main.sublime-menu’ file. Save and close both files.&quot;caption&quot;: &quot;SublimeREPL: py3.6ase - IPython&quot;&quot;id&quot;: &quot;repl_py3.6ase_ipython&quot;Setting keybindings for REPLThere is no default keybindings for SublimeREPL, but user defined keybindings can be added via ‘Preferences/Key Bingdings’. The parameters required for defining key bindings are the same as defining their captions, except an extra keyword &quot;keys&quot;. Copy and past the contents in ‘Default.sublime-commands’ and insert a &quot;keys&quot; line on the top of each command.{ &quot;keys&quot;: [&quot;f5&quot;],// Run the current script with Python 3.10 &quot;caption&quot;: &quot;SublimeREPL: py3.6ase - RUN current file&quot;, &quot;command&quot;: &quot;run_existing_window_command&quot;, &quot;args&quot;: { &quot;id&quot;: &quot;repl_py3.6ase_run&quot;, &quot;file&quot;: &quot;config/py3.6ase/Main.sublime-menu&quot;}},{ &quot;keys&quot;: [&quot;ctrl+f5&quot;],// Run PDB of the current python script &quot;caption&quot;: &quot;SublimeREPL: py3.6ase - PDB current file&quot;, &quot;command&quot;: &quot;run_existing_window_command&quot;, &quot;args&quot;: { &quot;id&quot;: &quot;repl_py3.6ase_pdb&quot;, &quot;file&quot;: &quot;config/py3.6ase/Main.sublime-menu&quot;}},{ &quot;keys&quot;: [&quot;ctrl+shift+f5&quot;],// Open the shell &quot;caption&quot;: &quot;SublimeREPL: py3.6ase&quot;, &quot;command&quot;: &quot;run_existing_window_command&quot;, &quot;args&quot;: { &quot;id&quot;: &quot;repl_py3.6ase&quot;, &quot;file&quot;: &quot;config/py3.6ase/Main.sublime-menu&quot; }},The code above indicates the settings of key bindings: F5 - Run the opened script in the py36ase environment Ctrl+F5 - Run PDB debugger for the opened script in the py36ase environment Ctrl+Shift+F5 - Open the py36ase shell for interactive commands.Syntax check and code completionBoth features are integrated into the Anaconda package. After installing it via Package Control, several important properties should be specified by opening ‘Preferences/Package Settings/Anaconda/Settings - User’ and setting it as follows:{ &quot;python_interpreter&quot;:&quot;D:/Anaconda3/envs/py3.6ase/python.exe&quot;, &quot;suppress_word_completions&quot;:true, &quot;suppress_explicit_completions&quot;:true, &quot;swallow_startup_errors&quot;:true, &quot;anaconda_linting&quot;:true}The proper interpreter should be specified in the first line. To avoid the error report when launched, set &quot;swallow_startup_errors&quot; to be true. To close the limit of 79 characters per column, set &quot;anaconda_linting&quot; to be false. The Anaconda package is automatically launched when opening a python script.Pep8 coding standardTo automatically check and fit python scripts into the Pep8 style, the AutoPep8 package is suggested. It does not require extra settings after finishing the installation. The default key bindings (‘Preferences/Package Settings/AutoPep8/Key Bindings - Default’) are: Ctrl+8 - Examine the script and show the previews of modifications; Ctrl+Shift+8 - Examine the script and directly modify it." }, { "title": "CRYSTAL known issues", "url": "/posts/CRYSTAL17-known-issues/", "categories": "Research, DFT", "tags": "CRYSTAL, regular inspection", "date": "2022-01-23 11:43:38 +0000", "snippet": "In this post are listed some known issues about CRYSTAL, including CRYSTAL17 v1.0.2 and CRYSTAL23 v1.0.1. Only problems with its source code are included, for other issues related to usages, please refer to other posts. Note, the majority of the issues are ‘imperfections’ rather than ‘bugs’. Special thanks to N.M.H, a main developer, for inspecting the source codes.Tests of the parallel edition are performed on Imperial cluster and ARCHER2 UK national supercomputer. Tests of the serial Linux edition are performed on Debain WSL2, Windows 21H2. Tests are performed from Feb. 2021 till the last updated date. The contents of this webpage are checked regularly.Basis set EIGS parallel only - The bug in printout of overlap matrix eigenvalues The diagonalization of the overlap matrix is distributed to individual cores according to the number of irreducible k points during parallel computing. The core in charge of printing will end the output file early when the number of cores used is larger than the number of k points due to the signal from spare cores. No eigenvalue will be printed out in this case. Only the exact TELAPSE and TCPU are printed at the end of the output file. SOLUTION The number of cores should be smaller than the number of irreducible k points (see the pre-SCF section of the .out file) when parallel CRYSTAL is used. BASISSET - A noticeable issue about its incompatibility with the END keyword. When specifying the pre-defined basis set names using BASISSET, the END keywords of geometry block and basis set block should be removed in case of error in reading input deck. BASISSET + def2-SVP - CRYSTAL23 A noticeable issue about the obsolete warning message The following warning message is obsolete and not true. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! WARNING !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! This is a molecular basis set! It might contain basis functions with an angular momentum (AM) higher than 3 (e.g. g-funcitons). Since CRYSTAL only supports functions with an AM of up to 3 (f-functions) they are removed from the basis. Keep that in mind when comparing results to molecular codes! !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!: SOLUTION Ignore it.Exchange-Correlation functional &amp;amp; related HYBRID SR-OMEGA MR-OMEGA LR-OMEGA both editions - A noticeable issue about their incompatibility. Fock hybrid percentage and short/medium/long rangeness cannot be modified simultaneously. SR-OMEGA, MR-OMEGA, and LR-OMEGA are only applicable to pre-defined range-separated functionals. SOLUTION The current situation is acceptable unless for developing new hybrid functionals, which is a delicate thing. The code also supports user-defined range separation of PBE based hybrid functionals - the keyword LSRSH-PBE is compatible with HYBRID. SR-HYB_WB97X - A bug with the keyword Used for tuning the short-range HF mixing percentage. Does not work at all because the code cannot recognize ‘wB97X’. SOLUTION Unknown. DFTD3 gCP - A noticeable issue that this sub-block is closed by END keyword only. Code does not recognize END keywords with suffixes for differentiating proposes, such as ENDD3. FUNC of DFTD3 - A bug that some functionals claimed to support actually cannot perform auto-parameterization. Test performed on M06-2X functional. For the list of available functionals please refer to Obtain parameter lists for Grimme’s DFT-D3 and gCP methods. SOLUTION Turn to the current coefficient pages (BJ damping and zero damping) of DFT-D3 for parameters and enter them manually. FUNC of DFTD3 Parallel edition - A noticeable issue about incompatibility of newly published functionals DFTD3 only recognizes the supported functionals and that goes beyond its own block. FUNC keyword will not cover the setups if a functional unsupported is defined in DFT block, which means users cannot cheat the code with a supported functional name at FUNC keyword and manually modify all parameters for the functional actually used. SOLUTION Unknown. Geometry optimization ITATOCEL RESTART - An incompatible bug in certain conditions. Cell parameter optimization is launched as the initial step of ITATOCEL. If the optimization is interrupted at the atomic coordinate optimization step, the restarted optimization will still begin from the cell parameters, leading to the error message OPTIMIZATION TYPE CHANGED. SOLUTION Manually set the option to ATOMONLY and restart. Then use ITATOCEL to check the convergence of cell parameters again. Frequency &amp;amp; DFPT PHONBANDS.DAT - CRYSTAL17, 23 not tested The bug in printout of phonon bands The discontinuous points of phonon dispersion curves at the high-symmetric points originate from a bug in source code. The 2 ends of every segment are duplicated during calculation, which the printout option fails to consider. SOLUTION Use the fort.25 file instead. MODES - The change of default settings The MODES command is the default option for most of cases. Howver, it is deactivated by the BANDS command, with the information INFORMATION **** INPFREQ **** BANDS: MODES PRINTING DISABLED. USE KEYWORD MODES TO ENABLE.. Solution To examine the eigenvectors of mass-weighted Hessian matrices during phonon band calculations, insert MODES in the FREQCALC block. Or an alternative is suggested to make the output clearer: Run frequency calculations at Γ first and restart the calculations for phonon bands. fort.9 tested on - A noticeable issue about empty binary wavefunction file for restarted jobs Unlike optimization module, the frequency module does not save binary wavefunction files (fort.9) of subsequent SCF calculations, so the fort.9 file for a restarted calculation is empty. SOLUTION Use the fort.9 file of the initial run. BIPOSIZE - A memory allocation bug about exceeding disk quota The keyword BIPOSIZE defines the size of bi-electron integral buffer. By default it is 32Mb. That limit might be exceeded when using large basis sets / screened hybrid functionals. Typically that issue can only lead to a warning message during SCF calculations and slightly sluggish computation, because the system has to re-allocate disk quota and restart calculations after the bi-electron integral exceeds the pre-defined buffer. However, such re-allocation is neither saved in SCF output files nor passed to the frequency calculation module. When involving a new SCF calculation ‘within’ the module (the known examples are RESTART and QHA), ‘Disk quota exceeded’ error will be reported and the program will exit without re-allocating the disk quota. NOTE According to tests, missing BIPOSIZE might kill other running jobs as well. SOLUTION For RESTART, do an SCF trial run for large systems and set BIPOSIZE no smaller than the output value. For QHA, no solution is known since it inevitably launches multiple harmonic calculations. MULTITASK - A file I/O bug about restarting multitask calculations This keyword allows multiple SCF calculations running simultaneously when generating the numerical force constant matrices. The FREQINFO.DAT.tsk[n] files are generated during the calculation and the FREQINFO.DAT file is generated at the end. Restarting a MULTITASK run with either FREQINFO.DAT.tsk[n] or FREQINFO.DAT file is impossible, no matter whether the previous run is either finished or killed. SOLUTION Unknown. Properties CPHF - A noticeable issue about supported exchange-correlation functionals. Only a limited number of functionals are supported in CPHF/KS method. Listed in the manual. PBAN - A noticeable issue about projected charge density of conduction bands. Charge density projection are obtained directly from KS eigenvalues and will be exactly 0 if projected onto unoccupied bands, which is different from DOS curves, in which case the density above the Fermi level is non-zero. SOLUTION To visualize the spatial shape of CBM, compute crystalline orbitals with the keyword ORBITALS instead. Developers BASISSET + ‘def2’ basis set family - A noticeable issue that non-UTF-8 encoded character is printed out when specifying BASISSET with ‘def2’ basis sets. The non-UTF-8 encoded character lies in the ‘ä’ of the following line:Fully Optimized Contracted Gaussian Basis Sets for Atoms Li to Kr. A. Schäfer, H. Horn and R. Ahlrichs; J. Chem. Phys. 97, 2571 (1992). This issue leads to probable errors when decoding files. For example, when using reading files with python:&amp;gt;&amp;gt;&amp;gt; file = read(filename, &#39;r&#39;)The command above leads to error message: ‘Non UTF-8 encoded character.’ Either delete ‘ä’ or add the option to skip the character can solve this problem:&amp;gt;&amp;gt;&amp;gt; file = read(filename, &#39;r&#39;, errors=&#39;ignore&#39;)" }, { "title": "Zotero 配置坚果云", "url": "/posts/zotero%E9%85%8D%E7%BD%AE%E5%9D%9A%E6%9E%9C%E4%BA%91/", "categories": "Technique, others", "tags": "Zotero, windows", "date": "2022-01-22 16:21:09 +0000", "snippet": "本文简单总结一下为Zotero配置坚果云，在线同步文献库的方法。坚果云可能是国内唯一支持WebDAV的同步盘，而国外可选择的软件则有Onedrive, Google Drive等，但是因为不幸被墙而无法使用。设置日期2022年1月9日，系统Windows 10 21H2。Zotero简介Zotero是一个开源免费的文献管理和引文创建软件。通行的类似软件还有Endnote和Mendeley。前者的历史最悠久，使用人数也最广，基本上所有学术论文库都支持导出Endnote格式的引文。但缺点一是收费，二是闭源，导致它的跨操作系统的支持度差、功能没有后两个多。Mendeley则是免费软件，其格式也是常用的引文格式之一，并且比Endnote更灵活，支持安卓、苹果（手机及电脑）、Windows，Linux，同时也具备了Microsoft Word和Chrome插件。Zotero的支持度不亚于Mendeley，并且得益于开源社区的支持，能够读写几乎所有常见格式的引文数据，并且有丰富的引文格式库。美中不足之处在于它不能可视化地设计引文模板。用户若要设计自己的引文格式必须使用xml语言。关于Zotero文献库格式的理解当把一篇PDF格式的论文拖动到Zotero中时，软件便会自动抓取PDF的元数据并创建一个文献条目，而原本的文件便会以附件的形式放在条目下。若需要存档其它相关文件，譬如论文补充材料、笔记等时，只要在同一条目下再加附件即可。同时，软件会把所有的文件以它自己能读懂的格式放到本地的Zotero/storage/下名称意义不详的子文件夹里，而这个文件夹使用者很难找到，也没有必要打开。因此使用者阅读存档文件的唯一办法就是从Zotero中访问文件。整个文件夹的结构一般是这样：flowchart TD subgraph Zotero/storage/ subgraph literature1/ a1(.ztoero-ft-info) a2(.ztoero-ft-cahe) a3(paper.pdf) a4(note.md) end B(literature2/) C(literature3/) D(...) end main(Zotero/) -- contains --&amp;gt; Zotero/storage/ main(Zotero/) -- contains --&amp;gt; data(zotero.sqlite) data(zotero.sqlite) -.organizes.-&amp;gt; Zotero/storage/同时，在上一级的Zotero/文件夹下，还有几个记录整个文献库信息的十六进制文件zotero.sqlite*。按照我的理解，这个文件相当于一个目录，记录了文献库的结构，如文献库里的文件夹名称，内容，关系。软件根据这个目录在storage/文件夹中寻找对应的文献信息和附件，并在GUI中显示整个文献库的结构和内容。Zotero的同步规则下载安装Zotero后，若要实现不同设备间文献的同步，必须用邮箱注册Zotero账号。由上一节的分析可以看出，要实现跨设备的同步，必须同时同步目录文件Zotero/zotero.sqlite*和文献数据文件夹Zotero/storage/。在完成注册后，Zotero会免费为用户提供不限量的目录同步空间以及300MB的文献数据同步空间。因此，在配置时考虑如何用第三方软件同步文献数据文件夹即可。设置坚果云方法辨异目前使用云盘进行文献库的方式有两种，一种是配置WebDAV同步文件夹Zotero/storage/，一种是设置软链接。前者只能通过坚果云实现，而后者可以通过任意同步盘实现。虽然后者乍看十分美丽，实际上十分愚蠢（更荒唐的是居然是坚果云官方发的，简直误人子弟），在这里批判一下。软连接方式的思路是，在名称为乱码的Zotero/storage/子文件夹下只保存文献信息而不保存文献实体，在条目下附加一个链接指向附件的实际存放位置。这样一来，结合ZotFile插件的批量重命名（同时也能重命名文件的上一级路径）功能，就可以批量地把文献转移到一个专门的，名称可读的文件夹里，从而方便查看。这种方式看似完善，却忽略了一个事实 - 并不是所有文件都有完整的元数据。若把Zotero作为一个知识分类整理的软件，那文献库里常会有ppt、网页快照、课堂讲义等非正式的出版物。而对于经常接触中文期刊的人来说，中文论文的元数据也常常无法获取。这样一来所谓“可读”文件夹中的文件是缺失的，因为ZotFile并不会按照规则重命名一个检索不到数据的文件，那些文件将残留在原来的文件夹里。而至于“将文献按照期刊/年份/作者归类到对应文件夹中方便查找”这种做法也完全没有意义，因为使用者可以在Zotero软件中方便地按照这些条件筛选文献，再导出为带或不带附件的多种文献格式。只要知道对方使用的文献管理方法（对于一个合格的研究者，这是基本技能）即可。如果只是复制少数几篇的话，完全可以用鼠标拖动进行复制。而如果是分享无法抓取元数据的文件的话，在Zotero中进行操作更是唯一的方法。总而言之，这种方法从根本上失去了自动进行文献管理的意义。而使用WebDAV同步更加简明，并且能收获更好的效果。因此这里只介绍WebDAV的配置方法。坚果云同步的相关问题目前坚果云免费版的规则是限制每月上传下载流量（1G/3G每月），不限制总空间和速度，因此适用于初步接触科研，文献积累还不十分多的用户。而收费版则是限制了云盘空间，适合已经有一定积累的用户。需要说明的是，不能指望“购买一个月会员把所有储备上传好，后面再降级成免费版”这种操作，因为付费版到期后会跳出更小的空间限制，在付费期间上传的文件，超出空间限制的部分会被强制要求删除（当然，可以选择删除哪些部分）。这也是坚果云受到诟病的一个问题。坚果云配置WebDAV需要设置针对特定软件的密码。在网页端的右上角账户名处选择“账户信息”，页面跳转后选择“安全选项”，找到“第三方应用管理”并点击“添加应用”，系统将自动生成密码。配置Zotero打开Zotero, 选择’Edit/Preferences/Sync/settings’, 如图配置WebDAV。同时也可以看到，对于Zotero，文献库结构和附件确实是分开同步的。但是需要注意，用坚果云同步Zotero/zotero.sqlite*并不明智，因为软件一打开该文件就在占用状态。坚果云解除文件的占用并不及时，若一台设备在退出软件后就断网或关闭，文件将一直处在占用状态，导致其他设备上的Zotero无法正常使用。Zotero 默认把文件存在C盘，但可以改。打开’Edit/Preferences/Advanced/Files and Folders’，更改’Data Directiory Location’。注意目录文件和文献信息的存放位置将同时更改。上一个“Linked Attachment Base Directory”就是软链接指向文件的存放位置，可以不管。一些插件推荐外挂插件为.xpi格式，需要自己下载并搭载。下载好后选择’Tools/Add ons/Install Add on From File’（弹窗右上角的齿轮）。安装好后重启Zotero即可。ZotFile 可以利用元数据和正则表达式对PDF文件进行重命名。选择’Tools/ZotFile Preferences/Renaming Rules’。下图所示的命名规则即“作者_年份_标题”。 可以指定一个路径，默认将路径中的文件添加到Zotero中。选择’Tools/ZotFile Preferences/General Settings’。 可以实现与平板的文件往来。对于Android设备，安装Zoo for Zotero并设置WebDAV即可，不需配置ZotFile。对于苹果设备则需要通过该选项实现附件的同步。未测试苹果设备。Markdown Here 方便地实现Markdown语法编写笔记。笔记作为文献的附件存放在相应的文献条目下。 下载Thunderbird版本" }, { "title": "VASP resources", "url": "/posts/VASP-resources/", "categories": "Research, DFT", "tags": "VASP", "date": "2022-01-22 11:05:20 +0000", "snippet": "In this post are listed some useful learning resources of the (probably) most popular planar wave basis set ab initio simulation package, VASP. Due to its popularity, there are tones of resources available online. Here only a minor port of them are listed, which, as I found, particularly useful. This post is just a list of resources I collected during my ‘VASP era’ (19-21), so regular updates might be unavailable since I do not work on VASP any more. Resources checked Jan. 22-2022.Official sitesVASP Wiki - The online VASP manuals, tutorials etc. Maintained and released by VASP developers, it is certainly the most reliable source to learn VASP.VASP forum - The official forum for VASP users. For most of times, VASP developers are very active in this forum - their replies can be found under many posts.The old website of VASP, http://cms.mpi.univie.ac.at, has been unfortunately abandoned since late 2020. Old forum posts are believed to be safely transferred to the new forum, yet the their original links are no longer valid. Besides, the retired online manual is not available. The contents of the PDF manual are the same as its online counterpart, so they are out-of-date as well. The only reliable manual for the current version of VASP is VASP Wiki.List of resources - The officially recommended tool kits for VASP simulations, which, I think, is better than any other recommendation.Other learning resourcesLearn VASP The Hard Way (LVASPTHW) - 中文 非常详细的初级到中高级教程，美中不足的就是稍显罗嗦。侯柱峰VASP手册 - 中文 入门级手册涵盖了VASP编译，SCF，几何结构优化的参数测试方法、选择技巧，以及电学、磁学、界面性质计算的建模与计算方法。需要注意手册只有2004和2005两个版本，部分方法（如几何结构优化的方法）已经过时，需要结合VASP Wiki批判学习。世事如棋的GitHub博客 - 中文 一些关于VASP以及配套工具使用方法的收录，讨论非常深入但是系统性不强。第一原理計算入門 - Japanese A collection of instructions for various ab initio codes. Focused on compiling / setting up VASP and related tools.PseudopotentialsThe pseudopotential files (POTCAR) for VASP are maintained and regularly updated by VASP developers. Sadly they are only available for licensed users from the download portal. Some ‘unofficial’ resources might be available, but constructing pseudopotentials is a delicate thing, so check the instructions &amp;amp; editions carefully before using.Standard solid-state pseudopotentials, SSSP, A web gallery of open source pseudopotentials.VisualizationThe VASP format is widely supported by various mainstream visualization software.VESTA - The visualization software supporting various geometry formats (but not CRYSTAL). Applicable for Windows, MacOS, and Linux. Known Issue The old 3.4.x versions, except 3.4.0, get problems when visualizing the charge density file (CHGCAR). Not a problem for now since the latest version is 3.5.7.Pre-processing &amp;amp; ComputationvdW-DF - Including vdw_kernel.bindat and vdw_kernel.bindat.big_endianbinary files.The latter one is for big endian devices. Both are available for licensed users from the download portal. Unofficial copies might be available. It might be possible to automatically generate a new one by VASP during calculations, but the time consumption skyrockets, probably for days. Place it in the job folder and edit INCAR as instructed.constr_cell_relax.F - Perform geometry optimizations along the specified direction(s) only.The script is stored in src/ and is disabled. Refer to the comments in the script for instructions to activate this function. Here an example is provided:SUBROUTINE CONSTR_CELL_RELAX(FCELL)USE PRECREAL(Q) FCELL(3,3), SAVE(3)LOGICAL FILFLGINTEGER ICELL(3)INQUIRE(FILE=&#39;OPTCELL&#39;,EXIST=FILFLG)IF (FILFLG) THEN ! read in OPTCELL OPEN(67,FILE=&#39;OPTCELL&#39;,FORM=&#39;FORMATTED&#39;,STATUS=&#39;OLD&#39;) READ(67,&quot;(3I1)&quot;) (ICELL(I),I=1,3) CLOSE(67) !WRITE(*,*) &quot;NOTICE: OPTCELL read in !&quot; DO I=1,3 SAVE(I)=FCELL(I,I) ENDDO FCELL=0.0d0 DO I=1,3 IF(ICELL(I)==1) FCELL(I,I)=SAVE(I) ENDDOENDIFRETURNEND SUBROUTINEPlace the script into src/ and re-compile VASP5.4. A new file, OPTCELL should be placed into the job folder. OPTCELL is a 3x3 integer, binary matrix (ICELL(3,3)). 0 denotes fixing the corresponding element of the cell matrix (FCELL) in POSCAR, while 1 means relax it. Update Jan. 22-2022 I recently got a copy of VASP6.1.2 source codes (via a private way), the situation remains unchanged.VTSTTools - For transition state search and reactions. Not really used.Bader - For atomic Bader charge analysis. Used with chgsum.pl script from VTSTTools.Although from a personal point of view, population analysis is somewhat ‘nonphysical’, and in many cases the results of Bader charge is even worse than the simpler Mulliken charge, but to the best of my knowledge, Bader analysis is the only available option for VASP.phonopy and phono3py - Typically for phonon dispersion and thermodynamic properties via finite displacement method.The formal one is written in Python 2 and the latter one in Python 3 (should be, I did not remember clearly. Generally speaking they are the same in features). Combined with VASP to analyze the symmetry of input geometry and displace the initial geometry along all the symmetrically nonequivalent directions for phonon calculations. It also has interface to other calculators including CRYSTAL.Raman-sc - A Python 2 package for Raman spectra simulation - not a mature edition.According to my preliminary tests only peak positions can be calculated correctly, nevertheless still an impressive achievement considering the lack of support of VASP in vibrational properties.Post-processingp4vasp - A powerful post-processing software with graphical user interfaceIt can be used to read, visualize, and export various electronic properties. Applicable for Windows, MacOS, and Linux. Based on vasprun.xml file, it can be launched by simply copying its executable file to the job folder. It can also used for structure visualization but not as beautiful as VESTA. Known issue Its information webpage has been down due to sever problems since late 2021. Only GitHub page is available now.VASPKIT - A light-weight tool kit for post-processing.No graphical interface, only available on Linux. Capable of dealing electronic and optic properties including band, DOS, electrostatic potential, differential charge/spin density and planar averaged properties." }, { "title": "Compile VASP 5.4.1 on Ubuntu/Debain Linux", "url": "/posts/Compile-VASP-5.4-on-Ubuntu-Linux/", "categories": "Technique, Parallel Computing", "tags": "VASP, linux", "date": "2022-01-18 17:07:32 +0000", "snippet": "This post is to briefly introduce available methods to compile VASP 5.4 on Ubuntu or Debain OSs. Tested on Debian WSL2, Windows 10 21H2, Jan. 9-21. VASP edition 5.4.1.05Feb16.Currently there are two mainstream compiling and parallelizing solutions for VASP: by Intel parallel studio + Ifortran, or by openmpi + gfortran. The former one is an almost ‘all-in-one’ solution and easier to compile, but a valid license number is needed, which can be requested free of charge via educational/academic email addresses. The latter one is based on GNU license and free of charge, but more difficult - libraries of gfortran, openmpi, and ScaLAPACK are needed and package dependency should be carefully checked. According to many online tests, if parameters in the ‘makefile.include’ file (see below) are set properly, there is only a negligible difference in performances of VASP running on Intel package or GNU packages.P.S. The author do not actually use VASP for research since July 2020, so the information provided here may not be up-to-date and well-maintained. Anyway, it is easy to get instructions from forums and Wiki.By IntelReferences A text, step-by-step guide on Ubuntu, in simplified Chinese. A video guide on CentOS, in Chinese.A recent issue with Intel parallel studioThe latest available edition of Intel parallel studio is XE 2020. Releases after that have been integrated into oneAPI and no new license number is released for the previous editions. Fortunately, oneAPI can be requested free of charge without a student license, and its usage is generally the same as the parallel studio. The environment used here is Parallel Studio XE 2020, which can still be obtained via ‘non-official’ sources.PrerequisitesFor a newly installed WSL2 Debain subsystem, many packages are missing, Packages listed below should be installed via sudo apt-get install at least before installing Intel parallel studio: libgtk-3* libxss1* libnss3 libgtk2.*common libpango-1* libasound2* xerver-xorgBesides, packages listed below should be installed at least before compiling VASP: rsync gccInstall Intel parallel studio Unzip the package with the tar -zxvf command and enter the folder. Type the command ./Install_GUI.sh and enter the installing environment. Follow the instructions to complete the installation. Set the environment variable for the Ifort compiler and the MKL library in ~/.bashrc. Substitute /your-intel-directory/ with the actual directory you place the folder. ~$ echo &quot;source /your-intel-directory/intel/bin/compilervars.sh intel64&quot; &amp;gt;&amp;gt; ~/.bashrc~$ echo &quot;source /your-intel-directory/intel/mkl/bin/mklvars.sh intel64&quot; &amp;gt;&amp;gt; ~/.bashrc~$ source ~/.bashrc Check whether the compiler has been successfully installed and set up successfully with the commands ifort -v, icc -v and echo $MKLROOT.Compile Intel fftw3 (Fast Fourier transformation)Enter the folder intel/mkl/interfaces/fftw3xf and type the command make libintel64 to compile Intel fftw3. The output is libfftw3xf_intel.a.PatchesSee below: By GNU/Get patchesCompile VASP Unzip the VASP package and enter the folder. Copy the file arch/makefile.include.linux_intel to the current directory, and rename it as makefile.include. Open makefile.include, find the line with OFLAG and substitute it with the line below: OFLAG = -O2 -xhost This command improves the performance of the compiled VASP. In the same directory, enter the command make all and wait.UsageThe compiled program is at the bin/ sub-folder. The most commonly used edition is vasp_std.To launch VASP, firstly load Intel mpi and then execute vasp_std in parallel:~$ source /your-intel-directory/intel/parallel_studio_xe_2020/psxevars.sh~$ mpirun -np [number of processors] VASP/directory/bin/vasp_std &amp;gt; printout.log A known issue with multi-node parallelizationAn issue has been identified with Intel Parallel Studio XE 2020 when parallelizing multiple nodes. Discussions can be found in this page. To address this problem, the following line, of which the exact meaning is unclear to me, should be inserted into the job submission script, or be entered in the command line, before the sentences executing parallel computations:~$ export UCX_TLS=ud,sm,selfBy GNUCompilation with GNU packages are more cumbersome because of the absence of a one-stop solution. Various packages and libraries are needed, and their dependencies and proper parameters should be checked carefully. The steps below were tested reliable in Jan. 2020 on a WSL1 Debain subsystem. However, error was reported when compiling the same source codes in Jan. 2022, saying that inconsistency in data type was detected for a certain variable. Not sure whether it originates from a library assumed to be unnecessary (libscalapack-openmpi1, see below). This section is listed here as a supplement.Reference: A text guide to compile VASP5.4.1 with GNU software, in Japanese. Another text guide in English.PrerequisitesIn practise the packages in both references are installed before VASP is successfully compiled. Therefore many packages are included (and some of them might be redundant):Compilers csh g++ gfortran g++build-essentialMPI libopenmpi-devLinear Algebra &amp;amp; Parallelization liblapack-dev libblas-dev libtmglib-dev libatlas-base-dev libscalapack-mpi-dev libscalapack-openmpi1 libscalapack-openmpi-devlibscalapack-openmpi1 is an old-fashioned package and not available via apt-get install. An alternative is downloading it from the Debain webpage manually checking its dependency. It depends on packages below: gcc-6-base libgofortran3 libopenmpi2(old stable) libblacs-openmpi1These packages are also recommended to be installed manually because of the version problem.Fast Fourier transformation libfftw3-dev libfftw3-3Synchronizing data rsyncGet patchesUnzip the VASP packages and enter the folder. Use the commands below to add patches to the source code:~$ wget http://cms.mpi.univie.ac.at/patches/patch.5.4.1.14032016.gz~$ wget http://cms.mpi.univie.ac.at/patches/patch.5.4.1.03082016.gz~$ gunzip patch.5.4.1.14032016.gz~$ gunzip patch.5.4.1.03082016.gz~$ patch -p0 &amp;lt; patch.5.4.1.14032016~$ patch -p0 &amp;lt; patch.5.4.1.03082016 Issue identified Jan. 9-21 Unfortunately due to the abandon of the old website, both links are invalidate. The VASP Wiki did not provide any updated resources for this issue, which influences all the patches for VASP5. Therefore, please check the descriptions of both patches and consider your propose of running VASP before continuing.Compile VASP Copy the file arch/makefile.include.linux_gfortran to the current directory, and rename it as makefile.include. Modify the file as follows. Check the directories in variables LIBDIR, OBJECTS, and INCS：# Precompiler optionsCPP_OPTIONS= -DMPI -DHOST=\\&quot;IFC91_ompi\\&quot; -DIFC \\ -DCACHE_SIZE=4000 -Davoidalloc \\ -DMPI_BLOCK=8000 -DscaLAPACK -Duse_collective \\ -Duse_bse_te -Duse_shmem -DtbdynCPP = gcc -E -P -C $*$(FUFFIX) &amp;gt;$*$(SUFFIX) $(CPP_OPTIONS)FC = mpif90.openmpiFCL = mpif90.openmpiFREE = -ffree-form -ffree-line-length-noneFFLAGS = OFLAG = -O2 -mtune=native -m64OFLAG_IN = $(OFLAG)DEBUG = -O0LIBDIR = /usr/lib/x86_64-linux-gnuBLAS = -L$(LIBDIR) -lblasLAPACK = -L$(LIBDIR) -ltmglib -llapackBLACS = -lblacs-openmpi -lblacsCinit-openmpi -lblacsF77init-openmpiSCALAPACK = -L$(LIBDIR) -lscalapack-openmpi $(BLACS)OBJECTS = fftmpiw.o fftmpi_map.o fftw3d.o fft3dlib.o \\ /usr/lib/x86_64-linux-gnu/libfftw3.aINCS =-I/usr/include -I/usr/lib/openmpi/includeLLIBS = $(SCALAPACK) $(LAPACK) $(BLAS)OBJECTS_O1 += fft3dfurth.o fftw3d.o fftmpi.o fftmpiw.o chi.oOBJECTS_O2 += fft3dlib.o# For what used to be vasp.5.libCPP_LIB = $(CPP)FC_LIB = $(FC) CC_LIB = gccCFLAGS_LIB = -OFFLAGS_LIB = -O1FREE_LIB = $(FREE)OBJECTS_LIB= linpack_double.o getshmem.o# Normally no need to change thisSRCDIR = ../../srcBINDIR = ../../bin make allUsageSimilar to VASP compiled by Intel parallel studio, the command to launch parallel computation is:~$ /usr/bin/mpirun.openmpi -np [number of processors] VASP/directory/bin/vasp_std &amp;gt; printout.log" }, { "title": "CRYSTAL Resources", "url": "/posts/CRYSTAL17-Resources/", "categories": "Research, DFT", "tags": "CRYSTAL, regular inspection", "date": "2022-01-17 17:23:43 +0000", "snippet": "Some useful resources for CRYSTAL learning and usage are listed in this page. All resources listed here are available online free of charge. Those currently not well-maintained ones are marked. Special thanks to my supervisors, N.M.H &amp;amp; G.M, and my colleague F.B. for kindly providing their suggestions. Contents of this page are regularly inspected.Current public release: CRYSTAL23 v1.0.1Manual &amp;amp; TutorialsUser manual - The ‘bible’ of all versions of CRYSTAL.CRYSTAL tutorial project - A collection of specially designed tutorials and workshopsThis website, of course :-)Basis setThe officially listed BSs - Published tests on periodic systems are available.Basis Set Exchange (BSE) - Tests on linear dependency needed. Available BSs are usually optimized for molecular systems.A collection of system-specific, Gaussian BSs optimized by Dr Mike Towler. Not maintained anymore.Geometry, Visualization and Data processingA main drawback of CRYSTAL package is the lack of matching geometry edit &amp;amp; visualization kit, making it comparatively not as user friendly as more popular codes like VASP/CASTEP. It should be noted that even though links here provide some temporary solutions, the images obtained are typically not satisfying from a point of publication, so coding seems to be the only choice for now. Meanwhile, for some keywords, there are print options for formats widely supported by mainstream visualization software - a typical example is the .CUBE format by the ECH3 keyword - which will not be discussed any more. Anyway, it should not be a real problem for any researcher with the basic programming capability. Maybe I will post my scripts to github someday when I am free and happy to do so.CRYSPLOT - An all-in-one visualization solution Known issues fort.25 (f25) file for DOSS/COOP/COHP: The Fermi level is not aligned to zero as routinely adopted. The calculated Fermi energy should be added to the values of the energy axis. PHONBANDS.DAT file for phonon band calculation: A bug with the print option of CRYSTAL17 source code. Data on reciprocal points next to the high-symmetric points might go missing - use the fort.25 file instead. MOLDRAW (visualizing the optimization steps and lattice vibrations) and TOPOND (topological analysis of electron density) have been integrated to CRYSPLOT. Jmol - Non-periodic system visualizer. The lattice boundaries can be visualized, but the atoms cannot be replicated along periodic directions. Used to visualize the molecular or crystalline orbitals (.molden file).J-ICE - Not tested A web-based, crystallographic version of Jmol.DL Visualize (DLV) 3 Developed in Daresbury laboratory, mainly by B. Searle. There was a release webpage which requires registration, but due to unknown reasons, now instead of the webpage, its repository is accessible, so currently it is open-source and free of charge.FINDSYM - Identify the space group from a CIF structure file and provide fractional coordinates of all the nonequivalent atomic sites.Atomic simulation environment (ASE) - A module to read and write the fort.34 (gui) formatted geometry file. Known issues The ase.io.crystal.write_crystal method has no symmetry analysis. Its output only has the P1 symmetry. ASE also has an interface to CRYSTAL14 to enable DFT/HF calculations within ASE. CRYSTALpytools with workflows In development - A pre- and post- processing tool co-developed by Computational Materials Science Group at Imperial College and Theoretical Chemistry Group at University of Torino. It adopts the heavily object-oriented fashion of Pymatgen and can easily cooperate with it. The latest stable release is accessible via pip. Installation instructions can be found on this page.Seek Path A web-based engine to generate high-symmetric paths in irreducible Brillouin Zone.Job submission scriptsThere are several job submission scripts available online. Considering the pros and cons of available scripts, I developed a new version for Imperial College HPC (CX1) based on Dr G. M.’s good example, which can be found on the Imperial-HPC-Jb-Submission page of the group github repository. Also check Job_Submitter_specific page for other environments.Note the setups of jobsubmitters are highly dependent on the environment of clusters. Currently 3 versions are developed, which covers the most common cases: For PBS batch system, using the Imperial College HPC (CX1) as the target environment. For Slurm batch system, using the UK national super-computing service ARCHER2 as the target environment. For local servers without batch system. Both serial and parallel versions of CRYSTAL are supported.Appendix: the output naming schemeA table is provided here to list the current naming schemes of the simulation outputs in my research group, with modifications. Even though this page is regularly inspection, oversight is inevitable. The complete and up-to-date naming scheme is available in the settings files of the job submission script folders.The input file and job submission file are named as jobname.xxx. NAME FORMAT DESCRIPTION Computation setups     jobname.d12 INPUT crystal input file jobname.d3 INPUT properties input file jobname.GAUSSIAN GAUSSIAN.DAT input in format of Gaussian98/03 Geometry information     jobname.gui fort.34 geometry, periodic jobname.xyz fort.33 geometry, atom coordinates only jobname.cif GEOMETRY.CIF geometry, cif format jobname.STRUC STRUC.INCOOR geometry, STRUC.INCOOR format jobname.FINDSYM FINDSYM.DAT input format for findsym General output     jobname.ERROR fort.87 error report jobname.out - screen output of program SCF     jobname.f9 fort.20, fort.9* binary wavefunction jobname.f98 fort.98 formatted wavefunction jobname.SCFLOG SCFOUT.LOG SCF output of subsequent steps jobname.PPAN PPAN.DAT mulliken population jobname.GRED GRED.DAT real space wavefunction for cryapi_inp jobname.KRED KRED.DAT k space wavefunction for cryapi_inp Optimization     jobname.HESSOPT HESSOPT.DAT Hessian generated by optimization jobname.OPTINFO OPTINFO.DAT optimisation restart data jobname.optstory/ opt* optimised geometry per step Frequency &amp;amp; spectra     jobname.FREQINFO FREQINFO.DAT frequency restart data jobname.f13 fort.13 binary reducible density matrix jobname.f28 fort.28 binary IR intensity restart data jobname.f81 fort.81, fort.80* binary localized Wannier function jobname.f25 fort.25 Phonon bands Crgra2006 format jobname.PHONBANDS PHONBANDS.DAT Phonon bands xmgrace format jobname.scanmode/ SCAN_DISP Displaced .gui along scanned mode jobname.IRDIEL IRDIEL.DAT IR dielectric function jobname.IRREFR IRREFR.DAT IR refractive index jobname.IRSPEC IRSPEC.DAT IR absorbance and reflectance jobname.BORN BORN.DAT Born tensor jobname.RAMSPEC RAMSPEC.DAT Raman spectra jobname.TENS_RAMAN TENS_RAMAN.DAT Raman tensor jobname.EOSINFO EOSINFO.DAT QHA and equation of states data CPHF/KS &amp;amp; dielectric constants     jobname.f32 fort.31, fort.32* CPHF/KS restart data jobname.DIEL DIEL.DAT dielectric constant Electronic bands &amp;amp; density of states     jobname.f25 fort.25 all Crgra2006 format data jobname.BAND BAND.DAT band xmgrace format jobname.DOSS BAND.DOSS dos xmgrace format Charge &amp;amp; 3D grid data     jobname.f31 fort.31 all 3D grid data jobname_CHG.CUBE DENS_CUBE.DAT 3D charge density Gaussian CUBE format jobname_SPIN.CUBE SPIN_CUBE.DAT 3D spin density CUBE format jobname.RHOLINE RHOLINE.DAT 1D charge density and gradient jobname.POINTCHG POINTCHG.INP Set dummy atoms with given charge jobname_POT.CUBE POT_CUBE.DAT 3D electrostatic potential CUBE format jobname.POTC POTC.DAT 1D electrostatic potential Molecular &amp;amp; crystalline orbitals     jobname.molden defname.molden molecular/crystalline orbitals for Jmol Note Dual file names in the middle column marked with ‘*’ stand for input file name (left) and output file name (right) respectively. Files are duplicated during calculation in case of losing important data." }, { "title": "Computerize the Skywatcher Virtuoso MiniDob Mount", "url": "/posts/Computerize-the-Skywatcher-Virtuoso-MiniDob-Mount/", "categories": "Interest, Astronomy", "tags": "telescope, DIY", "date": "2022-01-15 00:03:53 +0000", "snippet": "This post is to illustrate how to computerize the Skywatcher Virtuoso miniDob mount. Assembled and tested in July 2021. Some interesting discussions on the proper way to computerize it can be found in this discussion. Note: since everyone’s expectations and budgets may largely differ, no comment will be made here on whether the mount discussed is a rational choice.Background informationThe Skywatcher Virtuoso miniDob mount is a single-arm, alt-azimuth mount sold with a 90mm Maksutov-Cassegrain telescope or a 114mm Newtonian telescope since 2014. Now the price of a used one is typically around £200. It can be driven by built-in motors or by hands. The clutches ensure the manually pushed rotations are tracked and recorded as motor-driven motivations. The mount has already been computerized with a relatively simple program - auto-tracking is utilized if the true North and geographic latitude is set correctly. Besides, it can also cruise along a pre-set path. The official manual in PDF version is available online.Available connectors or ports for extensions are listed below: A dovetail slot for common telescopes; A 3/8” thread for common camera tripods locates at the bottom of the AZ clutch; An L-shape adaptor and an attached adaptor with 1/4” threads for common cameras; A RJ11/12 serial port for communication; A 12V 2A 5.5*3mm DC port for external power supply; A snap cable port for Canon cameras.SetupThe setup for the complete computerization of the miniDob mount is illustrated in the flow chart below.flowchart LR subgraph Telescope direction LR A(MiniDob mount) -- RJ11/12 serial port --&amp;gt; B(WiFi Adapter) end subgraph Cellphone direction LR B(WiFi Adapter) -.-&amp;gt; C(SynScan Android) end B(WiFi Adapter) -.-&amp;gt; D(SynScan Windows) subgraph PC direction LR D(SynScan Windows) -- drive --&amp;gt; E(ASCOM) E(ASCOM) -- drive --&amp;gt; F(Stellarium) endSetup the connectionTo utilize the computerization, the official solution is adopted to avoid unnecessary troubles. In fact, non-official WiFi/Bluetooth solutions are not noticeably competitive in costs. For the official solution, two critical parts are required: SynScan WiFi adaptor, plugged into the RJ11/12 serial port for wireless communication; SynScan App, installed on your computer or cellphone (Android only) for connection to the mount.Step 1 Plug the WiFi adaptor into the RJ11/12 serial port and turn on the switch.Step 2 Search available WiFi connection and connect your device to the WiFi spot named as ‘SynScan_WiFi_*’. By doing this the connected device will lose the Internet connection.Step 3 Launch the Synscan App, click on the ‘Connect’ button on the top of the window, select the available port and setup the connection. For PC users, probably no location sensor is available, so setting the latitude, longitude, and altitude manually is required. The panel can be found in ‘Settings/Location/’.After setting up the connection, the laptop or cellphone can already function as a hand controller for GOTO via SynScan App. For cellphone users, that is the end of story due to the limited choice of applications. For personal computer (PC) users, it is possible to track and control the current field of view (FoV) in the realistic sky via Stellarium.Live tracking via Stellarium PLUS on AndroidUpdate 21/01/21, Not testedNoticed in the new edition of Stellarium PLUS app, direct connection to SynScan Android is achieved. Will test that when I decide to buy that App (￡14.99) - Not an economic choice considering its price and features. Mobile observatory 3 Pro is a more rational choice, but no telescope control port is provided.Live tracking on personal computersIt is possible to achieve the live tracking of the telescope FoV on personal computers. Two software should be installed: ASCOM, the platform bridge between the SynScan driver and the virtual planetarium software; ASCOM driver for SynScan APP, to connect SynScan APP to ASCOM device hub; Stellarium, a virtual planetarium supporting ASCOM.Step 1 Make sure the driver has been correctly installed. Open ‘ASCOM Device Hub’, click ‘Tools’ and select ‘Setup’.Step 2 From the pop-out window, select the ‘Telescope Setup’ tab.Step 3 Click on the ‘Choose’ button. From the pull-down menu, select ‘SynScan App Driver’ and click OK. For properties, the default settings are okay.Step 4 Go back to the initial panel, click on the button ‘Connect Telescope’ and wait for the software to setup the connection.Step 5 After the connection to ASCOM successfully set, launch Stellarium. Click ‘Configuration window’ on the left and go ‘Plug-ins/Telescope Control’. Tick ‘Load at startup’ and restart Stellarium.Step 6 Following the same path as the previous step, click ‘configure’. From the pop-out window select ‘add a new telescope’.Step 7 In the ‘Telescope controlled by’ panel, select the ‘ASCOM’ option. Provide a proper name of the telescope in the ‘Telescope properties’ panel. Choose ‘SynScan App Driver’ from the pull-down menu of ‘Choose ASCOM Telescope’. Click ‘OK’.Step 8 Return to the ‘config’ panel. Select the telescope just created from the list and click ‘Connect’.Step 9 Return to the home screen. There will be a circle with name of the newly created telescope showing its live FoV.Usage &amp;amp; keybindings of Stellarium telescope control plug-inThe circle indicating the current aim will automatically track movements of the mount. The following keybindings are used to control the telescope via Stellarium. Ctrl + [x] Automatically aim the telescope [x] to the selected celestial body. [x] is the ID number of the telescope. Check the first column of telescopes list (Step 8). For example, to control ‘Skywatcher Mak 90’, press Ctrl 1. Alt + [x] Aim the telescope [x] to the center of the screen. Other optionsHand controllerThe most direct way to computerize the mount. However, it is also the most expensive option. Considering the conditions of field observations, especially in winters, its robustness makes it worth that price.Only the old version, SynScan V3 hand controller, is supported. Price for used ones varies, typically ~￡120.Wired connectionConnecting to the telescope mount via a serial-to-USB cable is possible and cheaper. However, its flexibility will be influenced. Besides, such connection is currently known to support Windows PC only. Another issue is that the tested serial-to-USB cable with the PL2303 chip is no longer available any more. The alternative with the FT232RL chip currently on the market does not fit the mount according to my test in July 2021.If, by any chance, the wired connection is set up properly, the driver, AZ GOTO do Armazém should be installed to make ASCOM recognize the mount and setup the connection to Stellarium, in a similar fashion to the SynScan driver.Other softwareStellarium is currently the most widely-supported and well-maintained virtual planetarium on Windows. Another software, Cartes du Ciel is also tested effective for both wireless and wired connections." }, { "title": "ARCHER2:Connection and basic commands", "url": "/posts/ARCHER2-Connection-and-basic-commands/", "categories": "Technique, Parallel Computing", "tags": "cluster, ARCHER2, CRYSTAL, regular inspection, linux", "date": "2022-01-14 22:00:08 +0000", "snippet": "This page is to briefly summarize the connection and usage of the UK national supercomputing service, ARCHER2.N.B. MAKE SURE YOU HAVE BEEN AUTHORIZED TO DO SO. Please note this page is not an official guidance. The author disclaims all responsibility for any trouble induced by the improper use of the information provided. For further details and technical supports, please visit user documentations of ARCHER2 and EPCC SAFE.Set up the connectionAn SSH key pair is needed every time the user logs in. Use the command below to generate a key pair:~$ ssh-keygen -t rsa -C your@email.comThen follow the instructions to generate the key pair. After generating that key pair, log into your SAFE account and add the generated key pair, saved in ~/.ssh/id_rsa.pub by default, to the corresponding Login account. After the system approves the request, connect to ARCHER2 via:~$ ssh login_account@login.archer2.ac.ukEnter the passwords for ARCHER2 account and for SSH public key in sequence. For first-time users, the default password is available in SAFE user page: In menu ‘Login accounts’, select the corresponding account, and click ‘View Login Account Password’ button on near the bottom of the screen. The default password is required to be substituted by a user-defined one during the initial login, and such change will NOT appear in the page ‘View Login Account Password’.For the detailed, step-by-step guide, please refer: https://docs.archer2.ac.uk/user-guide/connecting/#ssh-key-pairsGeneral usagesThe job schedulerThe Slurm job scheduler is used in ARCHER2. The job submission file should be named as jobname.slurm. Here lists some commonly used commands: sbatch jobname.slurm Submit the job ‘jobname’ squeue -u $USER List the information of jobs submitted (job ID, name, status, node number) sinfo Check the availability of resources scancel jobid Kill the job with the ID number ‘jobid’.Quality of service (QoS)Various QoS are provided to meet different computation needs. Here lists the capacities of commonly used QoS. For full details, please find https://docs.archer2.ac.uk/user-guide/scheduler/#quality-of-service-qos. QoS Name CPU per node Max nodes per job Max walltime Standard 128 1024 24:00 Note: Slurm schedules the submitted jobs in a walltime-increasing fashion, which means jobs with larger walltime will be left in the queue for longer, so if the condition permits, increasing the number of nodes to reduce the time consumption is preferred.CRYSTAL on ARCHER2A good example for the job submission file is provided in this webpage. It is pasted here for reference, with the modification suggested in the same page.A job submission script developed by myself and now used accross the group is open for download here.Note: To launch different calculations, substitute the MPPcrystal keyword in the script below with corresponding keywords: MPPcrystal crystal (.d12) calculation in the massive parallel edition Pcrystal crystal (.d12) calculation in a simple parallel edition Pproperties parallel properties (.d3) calculation Should be careful with the proper number of cores when MPPcrystal is activated. It follows the equation below:\\[n_{procs} \\geq n_{tasks} = n_{r} + n_{c} \\times WEIGHT\\]$n_{r}$ and $n_{c}$ are the number of k points with real or complex Fock matrices. $WEIGHT$ is the overloading of the diagonalization of the complex matrices. Its typical value is 1.5 ~ 2.5. (?)#!/bin/bash#SBATCH --nodes=2#SBATCH --ntasks-per-node=128#SBATCH --cpus-per-task=1#SBATCH --time=0:20:00# Replace [budget code] below with your full project code#SBATCH --account=[budget code]#SBATCH --partition=standard#SBATCH --qos=standard#SBATCH --export=nonemodule load epcc-job-envmodule load other-softwaremodule load crystal# Change this to the name of your input filecp tio2.d12 INPUTexport FI_MR_CACHE_MAX_COUNT=0 srun --hint=nomultithread --distribution=block:block MPPcrystal" }, { "title": "Connect to the Imperial Cluster", "url": "/posts/Connect-to-the-Imperial-Cluster/", "categories": "Technique, Parallel Computing", "tags": "cluster, Imperial RCS, regular inspection, linux, windows", "date": "2022-01-11 20:07:53 +0000", "snippet": "This page is to show how to set up the connection to Imperial cluster for the research computing services (RCS) and its usage. Contents of this page are regularly inspected.N.B. MAKE SURE YOU HAVE BEEN AUTHORIZED TO DO SO. Please note this page is not an official guidance. The author disclaims all responsibility for any trouble induced by the improper use of the information provided. For further details and technical supports, please visit the Imperial RCS website, the User Guide and high performance computing (HPC) service Wiki. The live status of the cluster is available from RCS status page. Brief introductions to parallel computing, queuing systems and the structures are provided in this post.Connection via VPNVPN is the easiest access to the Imperial cluster when users are off-campus. The cluster is directly accessible for on-campus visitors connected to the ‘Imperial-WPA’ WiFi.Set up Imperial VPNThe step-by-step, OS-specific guide: https://www.imperial.ac.uk/admin-services/ict/self-service/connect-communicate/remote-access/virtual-private-network-vpn/Set up ssh on WSLThe most convenient way to visit computing resources. For guidance of setting up WSL, refer this article: Set up Linux Subsystem on Windows 10. For alternatives / other OSs, refer: https://www.imperial.ac.uk/admin-services/ict/self-service/research-support/rcs/support/getting-started/using-ssh/The connection command:~$ ssh -XY username@login.hpc.ic.ac.ukNotes If ssh: command not found error is reported, install the ssh package by sudo apt-get install ssh (Ubuntu / Debian) or activate openssh service in OpenSUSE.~$ # Enable ssh services~$ service sshd start~$ # If firewall blocks the visit~$ sudo firewall-cmd --permanent --add-service=ssh~$ sudo firewall-cmd --reload -XY option can be omitted for most of cases, if you do not need GUI to run that program.An alternative connection optionSometimes the VPN service might be unstable or even not available. It is possible to channel through the gateway of the cluster:~$ ssh username@sshgw.ic.ac.ukThen you will log into an intermediate server. Use the command in the last section to visit the Imperial cluster.Upload &amp;amp; download filesUse the scp command to upload / download files. Its format is similar to ssh and cp command: scp /local/path/file_name username@login.hpc.ic.ac.uk:~/path/file_name Upload the local file scp username@login.hpc.ic.ac.uk:~/path/file_name /local/path/file_name Download the fileNote: if using the sshgw channel, scp will download the file to the intermediate server at first. You need another scp to download it to a local address. Same to upload.UsageBatch systemThe qsub job scheduler is implemented on Imperial cluster. availability Check the availability resources; qsub filename.qsub Submit the job ‘filename’; qstat Check the state of submitted jobs; qdel jobID Kill the process with the ID number ‘jobID’.SoftwareThe module commands can be used to examine/load publicly accessible modules. module avail List all the available modules; module load mod_name Load a specific module, ‘mod_name’; module rm mod_name Remove a specific module, ‘mod_name’; module list List all the loaded modules in the current environment; module help mod_name Check the instructions of the module ‘mod_name’.Note: There is a CRYSTAL14 module in the list. For users in NMH’s group, the latest CRYSTAL edition is available, so do not use that module.StatusThe current status of imperial cluster can be inspected by RCS status page.Compilation and ParallelizationIt is suggested to use the compilers and MPI available on CX1 if the you want to compile any code, as they are tuned according to the architecture to get the optimal performance. The Easy Build tool packages is available on CX1 by running module load tools/dev. The efficiency issue has been encountered before when I tried to use a self compiled OpenMPI.CX1 vs. CX2New Job partition guideThe new job partition guide is released in April 2022, which makes the old CX1/CX2 job partitions degenerate. For the new job sizing guide, refer to Wiki Page. The command availability is still useful to check the availability of resources.Note that the new job sizing scheme increases its flexibility, which is especially friendly for smaller, array-like jobs, at the price of increased inter-node communication cost (My own understanding, although received some agreements, not from my supervisor). To improve the efficiency of large jobs, increasing the number of processors per node rather than increasing the number of nodes is recommended. See Structure and usage of clusters for more information.Old job partitions - Only as a historical recordCX1 and CX2 are old names of Imperial clusters. Now they are merged, so you have access to both resources if logging in with the previous commands. Their job type and the core number per node are slightly different, which can be checked by availability. CX1 job partitions are listed under the name of ‘High-Throughput jobs’, and CX2 jobs are ‘High-End Parallel jobs’.~$ availabilityHigh-Throughput jobs: Nodes available for throughput : 0 (24hr) 0 (72hr) Nodes available for general : 0 (24hr) 0 (72hr) Nodes available for singlenode : 5 (24hr) Nodes available for multinode : 0 (24hr) 0 (48hr) Nodes available for large memory: 2 (24hr) 2 (48hr) Nodes available for GPU : 0 (24hr) 0 (48hr) Nodes available for debug : 4 (30min) Nodes available for 48c/128gb express : 3 (72hr) Nodes available for 32c/64gb express : 0 (72hr) Nodes available for pqnmh : 0 (shared) GPUs available: RTX6000 : 0/112 (24hr) 0/ 0 (48hr) High-End Parallel jobs: Nodes available for short ( select=1-18 ncpus=24 mem=120gb walltime=2:0:0 ) : 14 large ( select=18-72 ncpus=24 mem=120gb walltime=48:0:0 ) : 140, of which 0 are 28-core capability ( select=72-265 ncpus=28 mem=120gb walltime=24:0:0 ) : 22 express ( select=1-265 ncpus=24 mem=120gb walltime=72:0:0 ) : 0 P.S. Bug identified on Jan. 04 - 21 Probably due to the settings of the router, logging into the cluster via ‘Imperial WPA’ at MSRH, White City campus leads to a new system never seen before, CX3. availability and qdel are not available, with error messages: ‘availability: command not found’ and ‘qdel: Unknown Job Id 4977447.pbs-cx3’. (Job is on CX2) Solution Logging in via VPN and another WiFi, or use the command to specify CX2:~$ ssh username@login.cx2.hpc.ic.ac.uk Fixed Jan. 19 -21. For both campus and VPN connections, the old cx1 and cx2 addresses are merged to cx3: cx3.hpc.ic.ac.uk. Job types unchanged." }, { "title": "Set up the Linux Subsystem on Windows 10", "url": "/posts/Set-up-Linux-Subsystem-for-Windows-10/", "categories": "Technique, OS", "tags": "linux, windows", "date": "2022-01-11 12:36:54 +0000", "snippet": "This post is to show how to install and set up a proper Windows subsystem for Linux (WSL). Tested on Windows 10 Home 21H2, Jan. 07, 2022. Updated on Apr. 25, 2023.Resources:https://docs.microsoft.com/en-us/windows/wsl/install-manualhttps://docs.microsoft.com/en-us/windows/wsl/installhttps://github.com/DDoSolitary/LxRunOfflineEnable the WSL 2WSL 2 is a new edition of WSL with better compatibility with Windows. Some known bugs with WSL 1 can be fixed by upgrading to WSL 2: the inconsistent fonts of vim editor and the shell the initial mode set as ‘Replace’ in vim editorPrerequisites of WSL 2 x64 systems, should be Version 1903 or higher ARM64 systems should be Version 2004 or higherUpdate Windows settings open “Settings”, find and click on Apps &amp;amp; features From the right panel, find and click the Programs and Feature From the left panel, find and click the Turn Windows features on or off. Note, ‘Run as administrator’ needed. Select the check boxes for Virtual Machine Platform and Windows Subsystem for Linux from the menu and click OK. Restart your computer to install the updates.Install via Windows PowerShell Open the PowerShell as the administrator. Note: Search ‘PowerShell’ or Win + R, type ‘PowerShell’, enter. Type the command below to check available distributions:&amp;gt; wsl --list --onlineA Ubuntu WSL1 virtual machine seems to be installed by default in recent Windows 10 updates (in late 2022), but is not shown by wsl -l command. Using the following command will download the Ubuntu application from Microsoft store and activate the pre-installed virtual machine only - in which case the next section is skipped.&amp;gt; wsl --install --UbuntuIf other distributions are preferred, modify the --Ubuntu option into other distribution names listed on the screen.Install a Linux distributionThis step has been integrated into the previous step if you used the Automatic installation option. If not, install a distribution you like from Microsoft Store. Then launch the application and initialize the WSL as instructed.Upgrade from WSL 1 to WSL 2WSL1 is the previous version of WSL, which seems not to be a virtual machine platform of full functionality. It is suggested to check your WSL version and to upgrade it to WSL2. In PowerShell:&amp;gt; wsl -l -v NAME STATE VERSION* Ubuntu Running 1Then use the commands below and the distribution name (Ubuntu) to upgrade WSL:&amp;gt; wsl --shutdown&amp;gt; wsl --set-version Ubuntu 2Migrate WSL to another diskBy default, the Linux subsystem is installed in the system disk, which might easily get filled with application data, leaving only limited memory for WSL. It is possible to easily migrate the subsystem to another disk by a third party tool, LxRunOffline. Backing up or recovering your WSL can also be utilized with it.P.S., Nevertheless, the routine of allocating limited memory to system disk to mitigate the loss of system crash is somewhat out-of-date at the era of solid disks. Increasing the storage space of the system disk is preferred.After downloading the executable application, open PowerShell and cd to its directory. Type the command below (substitute Debian and D:\\Debian with your own distribution name and path):&amp;gt; .\\LxRunOffline.exe m -n Debian -d D:\\DebianThen a virtual disk is visible in the folder specified." } ]
